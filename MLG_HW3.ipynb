{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLG HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rita/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-19 15:17:26.913863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 15:17:28.450314: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-19 15:17:36.076780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-05-19 15:17:36.077021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-05-19 15:17:36.077034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bookIPNN': 0.7630446736162781, 'bookOPNN': 0.7596840523834419, 'bookPNN': 0.7518341524053948, 'bookCCPM': 0.7424491460611815, 'bookWDL': 0.7093089364684898, 'bookDCN': 0.7302810220618285, 'bookNFM': 0.7568314381827344, 'bookDeepFM': 0.7386060319249964, 'bookAFM': 0.7353113174115252, 'bookxDeepFM': 0.7524432051769194, 'movieIPNN': 1.1257715623148956, 'movieOPNN': 1.0723128454116133, 'moviePNN': 1.1457441626815474, 'movieCCPM': 1.053634406962656, 'movieWDL': 1.0492728323684728, 'movieDCN': 1.0530302980259754, 'movieNFM': 1.0942265873231904, 'movieDeepFM': 1.0515179004479969, 'movieAFM': 1.0710224032118236, 'moviexDeepFM': 1.0744275480292602, 'businessIPNN': 1.2039563606524462, 'businessOPNN': 1.1574377340755466, 'businessPNN': 1.1446729801067166, 'businessCCPM': 1.0781101968351026, 'businessWDL': 1.0570848609478811, 'businessDCN': 1.0804563918023302, 'businessNFM': 1.293179055678124, 'businessDeepFM': 1.0519467034898193, 'businessAFM': 1.083461280218211, 'businessxDeepFM': 1.147186490819429, 'bookUCF-s': 0.7564811612601006, 'bookUCF-p': 0.7739025387771253, 'bookICF-s': 0.7562839777895028, 'bookICF-p': 0.7735842952593969, 'movieUCF-s': 1.0172563467219868, 'movieUCF-p': 1.0120298826673264, 'movieICF-s': 1.0171996757236548, 'movieICF-p': 1.0110493167808736, 'businessUCF-s': 1.1039408212835053, 'businessUCF-p': 1.1652121494810417, 'businessICF-s': 1.1048697262119949, 'businessICF-p': 1.165001981832352, 'bookMF': 0.7195402649354384, 'movieMF': 0.9534203089643511, 'businessMF': 1.1082429242156786, 'bookFM': 0.7036099450214498, 'movieFM': 0.9496351163052212, 'businessFM': 1.0327142817035728, 'movieDIN': 0.2524024045889478}\n",
      "{'bookIPNN': 0.955981646740384, 'bookOPNN': 0.9086043659855502, 'bookPNN': 0.890112061447711, 'bookCCPM': 0.9575230611920952, 'bookWDL': 0.877498834095749, 'bookDCN': 0.8096409882705704, 'bookNFM': 0.9512699685234797, 'bookDeepFM': 0.8990917764940362, 'bookAFM': 0.8759769970785335, 'bookxDeepFM': 0.8823065199126064, 'movieIPNN': 0.8057275694959177, 'movieOPNN': 0.8720328577554367, 'moviePNN': 0.8565556279143822, 'movieCCPM': 0.8786725315538787, 'movieWDL': 0.7685889718924505, 'movieDCN': 0.8158027760348994, 'movieNFM': 0.8824248307569338, 'movieDeepFM': 0.800463696290241, 'movieAFM': 0.972227511225289, 'moviexDeepFM': 0.8020959861270232, 'businessIPNN': 0.6900055755494663, 'businessOPNN': 0.6931863176129511, 'businessPNN': 0.8155275561272879, 'businessCCPM': 0.9270941928110307, 'businessWDL': 0.9005994237673797, 'businessDCN': 0.8434689941950634, 'businessNFM': 0.6701014069498317, 'businessDeepFM': 0.8952035448370231, 'businessAFM': 0.9583412668379336, 'businessxDeepFM': 0.7336162047834573, 'bookMF': 0.9529610386127947, 'movieMF': 0.8523382564218218, 'businessMF': 0.8573676105402801, 'bookFM': 0.760454189007402, 'movieFM': 0.6260404641837294, 'businessFM': 0.6875192690378095, 'movieDIN': 1.0000000000000002}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob, json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
    "import torchfm\n",
    "\n",
    "\n",
    "\n",
    "config = {'test_size' : 0.2, \n",
    "          'n_epoch' : 20}\n",
    "rmse = {}\n",
    "ndcg_10 = {}\n",
    "recall_10 = {}\n",
    "\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "# with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "#     recall_10 = json.load(fp)\n",
    "print(rmse)\n",
    "print(ndcg_10)\n",
    "\n",
    "temp = pd.read_csv('results.csv', header = [0, 1], index_col = [0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(788898, 4)\n",
      "    user  book  rating  location\n",
      "0  10855   938       4      33.0\n",
      "1  10027     3       3     394.0\n",
      "(100000, 6)\n",
      "   user  movie  rating       time  age  occupation\n",
      "0   196    242       3  881250949    5           3\n",
      "1   186    302       3  891717742    4           4\n",
      "(184835, 3)\n",
      "   user  business  rating\n",
      "2     2       186       5\n",
      "3     2       205       5\n"
     ]
    }
   ],
   "source": [
    "def Data2List(path):\n",
    "    data = {}\n",
    "    os.chdir(path)\n",
    "    files = glob.glob('*.dat')\n",
    "    file_name = [x[:-4] for x in files]\n",
    "    for i in range(len(file_name)):\n",
    "        data[file_name[i]] = pd.read_csv(files[i], sep = '\\t', header = None)\n",
    "        # print(file_name[i])\n",
    "        # print(data[file_name[i]].head(2))\n",
    "    return data\n",
    "\n",
    "# Data Filtering\n",
    "# delete users who's interaction less than 3\n",
    "def del_less_than_3(data, target = 'user') :\n",
    "    temp = data[target].value_counts()\n",
    "    temp = temp.index[temp.values > 3]\n",
    "    data = data[data[target].isin(temp)]\n",
    "    \n",
    "    return data\n",
    "\n",
    "DoubanBook = Data2List('/home/rita/111/111-2MLG/HW3/data/DoubanBook')\n",
    "Movielens = Data2List('/home/rita/111/111-2MLG/HW3/data/Movielens')\n",
    "Yelp = Data2List('/home/rita/111/111-2MLG/HW3/data/Yelp')\n",
    "\n",
    "DoubanBook['user_book'].columns = ['user', 'book', 'rating']\n",
    "Movielens['user_movie'].columns = [\"user\",\"movie\",\"rating\",\"time\"]\n",
    "Yelp['user_business'].columns = ['user', 'business', 'rating']\n",
    "\n",
    "DoubanBook['user_book'] = del_less_than_3(DoubanBook['user_book'])\n",
    "Movielens['user_movie'] = del_less_than_3(Movielens['user_movie'])\n",
    "Yelp['user_business'] = del_less_than_3(Yelp['user_business'])\n",
    "\n",
    "# Merge user's feature\n",
    "# DoubanBook['user'] = pd.merge(left = DoubanBook['user_location'], right = DoubanBook['user_group'], on = 0, how = 'outer')\n",
    "# DoubanBook['user'].columns = ['user', 'location', 'group']\n",
    "# DoubanBook['user'] = pd.merge(left = DoubanBook['user_book'], right = DoubanBook['user'], on = 'user', how = 'left')\n",
    "DoubanBook['user'] = pd.merge(left = DoubanBook['user_book'], right = DoubanBook['user_location'], left_on = 'user', right_on = 0, how = 'left')\n",
    "DoubanBook['user'] = DoubanBook['user'].drop([0], axis = 1)\n",
    "DoubanBook['user'].columns = ['user', 'book', 'rating', 'location']\n",
    "\n",
    "Movielens['user'] = pd.merge(left = Movielens['user_age'], right = Movielens['user_occupation'], on = 0, how = 'outer')\n",
    "Movielens['user'].columns = ['user', 'age', 'occupation']\n",
    "Movielens['user'] = pd.merge(left = Movielens['user_movie'], right = Movielens['user'], on = 'user', how = 'left')\n",
    "\n",
    "Yelp['user'] = Yelp['user_business']   \n",
    "\n",
    "print(DoubanBook['user'].shape)\n",
    "print(DoubanBook['user'].head(2))\n",
    "print(Movielens['user'].shape)\n",
    "print(Movielens['user'].head(2))\n",
    "print(Yelp['user'].shape)\n",
    "print(Yelp['user'].head(2))\n",
    "path = '/home/rita/111/111-2MLG/HW3'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=None, shuffle=False)\n",
      "TRAIN: [2 3] TEST: [0 1]\n",
      "TRAIN: [0 1 3] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X)\n",
    "print(kf)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Typical RecSys Methods\n",
    "**UCF-s UCF-p ICF-s ICF-p** **MF** **FM** BPR-MF BPR-FM GBDT+LR XGB+LR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training UCF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7529  0.7576  0.7573  0.7601  0.7544  0.7565  0.0025  \n",
      "MAE (testset)     0.6053  0.6089  0.6085  0.6105  0.6061  0.6079  0.0019  \n",
      "Fit time          14.10   13.05   13.31   12.92   13.18   13.31   0.41    \n",
      "Test time         19.75   19.49   19.81   19.65   19.75   19.69   0.11    \n",
      "\n",
      "Start Training UCF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7722  0.7764  0.7737  0.7752  0.7719  0.7739  0.0017  \n",
      "MAE (testset)     0.6122  0.6156  0.6139  0.6149  0.6119  0.6137  0.0015  \n",
      "Fit time          15.67   15.58   16.23   17.48   16.13   16.22   0.68    \n",
      "Test time         19.15   19.39   19.27   19.29   19.36   19.29   0.08    \n",
      "\n",
      "Start Training ICF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7551  0.7581  0.7560  0.7531  0.7592  0.7563  0.0022  \n",
      "MAE (testset)     0.6069  0.6089  0.6075  0.6054  0.6104  0.6078  0.0017  \n",
      "Fit time          11.77   12.33   12.27   12.26   12.23   12.17   0.21    \n",
      "Test time         18.82   19.34   19.07   19.08   19.02   19.06   0.17    \n",
      "\n",
      "Start Training ICF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7733  0.7744  0.7738  0.7725  0.7739  0.7736  0.0007  \n",
      "MAE (testset)     0.6131  0.6137  0.6138  0.6122  0.6132  0.6132  0.0006  \n",
      "Fit time          15.57   15.50   15.78   15.68   15.86   15.68   0.13    \n",
      "Test time         18.71   19.29   18.95   19.07   18.99   19.00   0.19    \n",
      "\n",
      "Start Training UCF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0182  1.0161  1.0159  1.0213  1.0147  1.0173  0.0023  \n",
      "MAE (testset)     0.8044  0.8060  0.8037  0.8075  0.8019  0.8047  0.0019  \n",
      "Fit time          0.24    0.25    0.30    0.31    0.29    0.28    0.03    \n",
      "Test time         1.92    1.89    1.93    1.91    1.91    1.91    0.01    \n",
      "\n",
      "Start Training UCF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0125  1.0119  1.0109  1.0151  1.0097  1.0120  0.0018  \n",
      "MAE (testset)     0.8018  0.8037  0.8045  0.8053  0.8015  0.8034  0.0015  \n",
      "Fit time          0.41    0.34    0.48    0.46    0.44    0.43    0.05    \n",
      "Test time         1.90    1.89    1.93    1.91    1.90    1.91    0.01    \n",
      "\n",
      "Start Training ICF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0125  1.0112  1.0191  1.0204  1.0228  1.0172  0.0045  \n",
      "MAE (testset)     0.7996  0.7999  0.8052  0.8068  0.8101  0.8043  0.0040  \n",
      "Fit time          0.25    0.23    0.32    0.30    0.29    0.28    0.03    \n",
      "Test time         1.93    1.92    1.95    1.93    1.93    1.93    0.01    \n",
      "\n",
      "Start Training ICF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0211  1.0118  1.0115  1.0044  1.0064  1.0110  0.0058  \n",
      "MAE (testset)     0.8090  0.8028  0.8024  0.7981  0.7999  0.8024  0.0037  \n",
      "Fit time          0.42    0.34    0.48    0.46    0.44    0.43    0.05    \n",
      "Test time         1.91    1.90    1.96    1.94    1.91    1.92    0.02    \n",
      "\n",
      "Start Training UCF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1105  1.1055  1.0989  1.1023  1.1025  1.1039  0.0039  \n",
      "MAE (testset)     0.8556  0.8536  0.8459  0.8505  0.8478  0.8507  0.0036  \n",
      "Fit time          2.27    2.24    2.31    2.26    2.27    2.27    0.02    \n",
      "Test time         1.86    1.86    1.95    1.88    1.86    1.88    0.04    \n",
      "\n",
      "Start Training UCF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1716  1.1617  1.1663  1.1686  1.1578  1.1652  0.0049  \n",
      "MAE (testset)     0.9032  0.8981  0.8990  0.9025  0.8970  0.8999  0.0024  \n",
      "Fit time          3.12    3.10    3.19    3.17    3.14    3.14    0.03    \n",
      "Test time         1.69    1.69    1.76    1.70    1.69    1.71    0.03    \n",
      "\n",
      "Start Training ICF-s model\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1067  1.1042  1.1037  1.1029  1.1068  1.1049  0.0016  \n",
      "MAE (testset)     0.8518  0.8523  0.8520  0.8498  0.8509  0.8513  0.0009  \n",
      "Fit time          2.29    2.26    2.30    2.28    2.27    2.28    0.01    \n",
      "Test time         1.88    1.87    1.93    1.93    1.86    1.89    0.03    \n",
      "\n",
      "Start Training ICF-p model\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.1612  1.1639  1.1791  1.1584  1.1624  1.1650  0.0073  \n",
      "MAE (testset)     0.8976  0.8987  0.9080  0.8937  0.8994  0.8995  0.0047  \n",
      "Fit time          3.12    3.16    4.16    3.18    3.23    3.37    0.40    \n",
      "Test time         1.70    1.68    1.79    1.76    1.71    1.73    0.04    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CF = Collaborative Filtering\n",
    "# UCF-s / UCF-p / ICF-s / ICF-p\n",
    "# https://elevenzou.github.io/2019/02/16/Surprise%E5%BA%93%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/\n",
    "# 4 mins\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import KNNBasic\n",
    "from surprise.accuracy import rmse\n",
    "def Based_CF(data, feats, based = 'U', sim = 's') :\n",
    "    print('Start Training {}CF-{} model'.format(based, sim))\n",
    "    reader = Reader(rating_scale=(1,5))\n",
    "    data = Dataset.load_from_df(data[feats], reader)\n",
    "    based_dict = {'U' : True, 'I' : False}\n",
    "    sim_dict = {'s' : \"cosine\", 'p' : 'pearson'}\n",
    "    sim_options = {\"name\":sim_dict[sim],\"user-based\":based_dict[based]}\n",
    "    algo = KNNBasic(sim_options=sim_options)\n",
    "    a = cross_validate(algo, data, cv=5, verbose=True, n_jobs = 5)\n",
    "    print()\n",
    "    return a['test_rmse'].mean()\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)\n",
    "\n",
    "data_ls = [DoubanBook['user_book'], Movielens['user_movie'], Yelp['user_business']]\n",
    "feat_ls = [['user', 'book', 'rating'], [\"user\", \"movie\", \"rating\"], ['user', 'business', 'rating']]\n",
    "based = ['U', 'I']\n",
    "sim = ['s', 'p']\n",
    "for data, feats in zip(data_ls, feat_ls) :\n",
    "    # print(feats)\n",
    "    for b in based :\n",
    "        for s in sim : \n",
    "            name = feats[1] + '{}CF-{}'.format(b, s)\n",
    "            rmse_t = Based_CF(data, feats, b, s)\n",
    "            rmse[name] = rmse_t\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"w\") as fp:\n",
    "    json.dump(rmse, fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"w\") as fp:\n",
    "    json.dump(ndcg_10, fp)\n",
    "with open(\"./metrics/recall.txt\", \"w\") as fp:\n",
    "    json.dump(recall_10, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'book']\n",
      "Iteration: 1 ; error = 549.2433\n",
      "Iteration: 2 ; error = 544.3827\n",
      "Iteration: 3 ; error = 542.5937\n",
      "Iteration: 4 ; error = 541.1101\n",
      "Iteration: 5 ; error = 539.6039\n",
      "Iteration: 6 ; error = 537.5114\n",
      "Iteration: 7 ; error = 535.5107\n",
      "Iteration: 8 ; error = 532.3612\n",
      "Iteration: 9 ; error = 530.4623\n",
      "Iteration: 10 ; error = 529.1933\n",
      "Iteration: 11 ; error = 526.3051\n",
      "Iteration: 12 ; error = 524.2198\n",
      "Iteration: 13 ; error = 523.2564\n",
      "Iteration: 14 ; error = 520.8289\n",
      "Iteration: 15 ; error = 519.9230\n",
      "Iteration: 16 ; error = 517.9427\n",
      "Iteration: 17 ; error = 517.1025\n",
      "Iteration: 18 ; error = 515.6284\n",
      "Iteration: 19 ; error = 514.4382\n",
      "Iteration: 20 ; error = 514.1479\n",
      "test MSE : 0.4860 \n",
      "\n",
      "['user', 'movie']\n",
      "Iteration: 1 ; error = 268.2499\n",
      "Iteration: 2 ; error = 263.5227\n",
      "Iteration: 3 ; error = 258.9008\n",
      "Iteration: 4 ; error = 254.3870\n",
      "Iteration: 5 ; error = 250.9033\n",
      "Iteration: 6 ; error = 249.9556\n",
      "Iteration: 7 ; error = 247.7571\n",
      "Iteration: 8 ; error = 247.5062\n",
      "Iteration: 9 ; error = 244.6710\n",
      "Iteration: 10 ; error = 245.8280\n",
      "Iteration: 11 ; error = 244.4272\n",
      "Iteration: 12 ; error = 244.2788\n",
      "Iteration: 13 ; error = 244.3088\n",
      "Iteration: 14 ; error = 244.5905\n",
      "Iteration: 15 ; error = 244.1364\n",
      "Iteration: 16 ; error = 243.8816\n",
      "Iteration: 17 ; error = 243.3589\n",
      "Iteration: 18 ; error = 243.7585\n",
      "Iteration: 19 ; error = 242.5261\n",
      "Iteration: 20 ; error = 243.3650\n",
      "test MSE : 0.5800 \n",
      "\n",
      "['user', 'business']\n",
      "Iteration: 1 ; error = 366.3170\n",
      "Iteration: 2 ; error = 350.0903\n",
      "Iteration: 3 ; error = 335.0959\n",
      "Iteration: 4 ; error = 320.5801\n",
      "Iteration: 5 ; error = 307.8076\n",
      "Iteration: 6 ; error = 298.5276\n",
      "Iteration: 7 ; error = 290.3742\n",
      "Iteration: 8 ; error = 285.3123\n",
      "Iteration: 9 ; error = 280.8009\n",
      "Iteration: 10 ; error = 277.1138\n",
      "Iteration: 11 ; error = 274.2974\n",
      "Iteration: 12 ; error = 272.6453\n",
      "Iteration: 13 ; error = 270.1430\n",
      "Iteration: 14 ; error = 268.2377\n",
      "Iteration: 15 ; error = 266.8909\n",
      "Iteration: 16 ; error = 265.3589\n",
      "Iteration: 17 ; error = 264.5852\n",
      "Iteration: 18 ; error = 263.4969\n",
      "Iteration: 19 ; error = 262.4886\n",
      "Iteration: 20 ; error = 262.8567\n",
      "test MSE : 0.5570 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MF\n",
    "# https://albertauyeung.github.io/2017/04/23/python-matrix-factorization.html/\n",
    "# 9 mins\n",
    "class Matrix_Factorization():\n",
    "\n",
    "    def __init__(self, R, K, alpha, beta, iterations):\n",
    "        \"\"\"\n",
    "        Perform matrix factorization to predict empty\n",
    "        entries in a matrix.\n",
    "\n",
    "        Arguments\n",
    "        - R (ndarray)   : user-item rating matrix\n",
    "        - K (int)       : number of latent dimensions\n",
    "        - alpha (float) : learning rate\n",
    "        - beta (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initialize the biases\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            mse = self.mse()\n",
    "            training_process.append((i, mse))\n",
    "            # if (i+1) % 10 == 0:\n",
    "            if (i+1) % 1 == 0:\n",
    "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
    "\n",
    "        return training_process\n",
    "\n",
    "    def mse(self):\n",
    "        \"\"\"\n",
    "        A function to compute the total mean square error\n",
    "        \"\"\"\n",
    "        xs, ys = self.R.nonzero()\n",
    "        predicted = self.full_matrix()\n",
    "        error = 0\n",
    "        for x, y in zip(xs, ys):\n",
    "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(error)\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        Perform stochastic graident descent\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # Computer prediction and error\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # Update biases\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
    "\n",
    "            # Update user and item latent feature matrices\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        Get the predicted rating of user i and item j\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Computer the full matrix using the resultant biases, P and Q\n",
    "        \"\"\"\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)\n",
    "\n",
    "def MF(data, feats, target, K = 2, alpha = 0.01, beta = 0.01) :\n",
    "    print(feats)\n",
    "    train, test = train_test_split(data, test_size = config['test_size'])\n",
    "    a = data[feats[0]].max()\n",
    "    b = data[feats[1]].max()\n",
    "    R = np.zeros((a, b), dtype = np.float128)\n",
    "    train_x = np.array(train[feats])\n",
    "    train_y = np.array(train[target])\n",
    "    test_x = np.array(test[feats])\n",
    "    test_y = np.array(test[target])\n",
    "    for i in range(train_x.shape[0]):\n",
    "        # R[train.iat[i, 0] - 1, train.iat[i, 1] - 1] = train.iat[i, 2]\n",
    "        # R[train.at[i, feats[0]] - 1, train.at[i, feats[1]] - 1] = train.at[i, target]\n",
    "        R[train_x[i, 0] - 1, train_x[i, 1] - 1] = train_y[i]\n",
    "    \n",
    "\n",
    "    mf = Matrix_Factorization(R, K=K, alpha=alpha, beta=beta, iterations=config['n_epoch'])\n",
    "    training_process = mf.train()\n",
    "\n",
    "    temp = mf.full_matrix()\n",
    "\n",
    "    t = []\n",
    "    for i in range(test.shape[0]) :\n",
    "        t.append(temp[test_x[i, 0] - 1, test_x[i, 1] - 1])\n",
    "    t = np.array(t)\n",
    "    \n",
    "    test_y = np.where(test_y > 3, 1, 0)\n",
    "    t = np.where(t > 3, 1, 0)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(test_y, t))\n",
    "    ndcg = ndcg_score(test_y.reshape(1, -1), t.reshape(1, -1), k=10)\n",
    "    recall = recall_score(test_y.reshape(1, -1).squeeze(), t.reshape(1, -1).squeeze())\n",
    "    \n",
    "    print(\"test MSE : {:.4f}\".format(rmse, 4), '\\n')    \n",
    "    \n",
    "    return  rmse, ndcg, recall\n",
    "    # print(\"Global bias:\", mf.b, \"User bias:\", mf.b_u, \"Item bias:\", mf.b_i, sep = '\\n')\n",
    "    # x = [x for x, y in training_process]\n",
    "    # y = [y for x, y in training_process]\n",
    "    # plt.figure(figsize=((16,4)))\n",
    "    # plt.plot(x, y)\n",
    "    # plt.xticks(x, x)\n",
    "    # plt.xlabel(\"Iterations\")\n",
    "    # plt.ylabel(\"Mean Square Error\")\n",
    "    # plt.grid(axis=\"y\")\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)\n",
    "   \n",
    "data_ls = [DoubanBook['user_book'], Movielens['user_movie'], Yelp['user_business']]\n",
    "feats_ls = [['user', 'book', 'rating'], [\"user\", \"movie\", \"rating\"], ['user', 'business', 'rating']]\n",
    "for data, feats in zip(data_ls, feats_ls):\n",
    "    name = feats[1] + 'MF'\n",
    "    rmse_t, ndcg_t, recall_t = MF(data, feats[:-1], feats[-1], K = 5, alpha = 0.1, beta = 0.15)\n",
    "    rmse[name] = rmse_t\n",
    "    ndcg_10[name] = ndcg_t\n",
    "    recall_10[name] = recall_t\n",
    "    \n",
    "with open(\"./metrics/rmse.txt\", \"w\") as fp:\n",
    "    json.dump(rmse, fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"w\") as fp:\n",
    "    json.dump(ndcg_10, fp)\n",
    "with open(\"./metrics/recall.txt\", \"w\") as fp:\n",
    "    json.dump(recall_10, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'book']\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.31985\n",
      "-- Epoch 2\n",
      "Training MSE: 0.29114\n",
      "-- Epoch 3\n",
      "Training MSE: 0.27828\n",
      "-- Epoch 4\n",
      "Training MSE: 0.26993\n",
      "-- Epoch 5\n",
      "Training MSE: 0.26389\n",
      "-- Epoch 6\n",
      "Training MSE: 0.25919\n",
      "-- Epoch 7\n",
      "Training MSE: 0.25542\n",
      "-- Epoch 8\n",
      "Training MSE: 0.25227\n",
      "-- Epoch 9\n",
      "Training MSE: 0.24957\n",
      "-- Epoch 10\n",
      "Training MSE: 0.24721\n",
      "-- Epoch 11\n",
      "Training MSE: 0.24513\n",
      "-- Epoch 12\n",
      "Training MSE: 0.24328\n",
      "-- Epoch 13\n",
      "Training MSE: 0.24159\n",
      "-- Epoch 14\n",
      "Training MSE: 0.24006\n",
      "-- Epoch 15\n",
      "Training MSE: 0.23865\n",
      "-- Epoch 16\n",
      "Training MSE: 0.23735\n",
      "-- Epoch 17\n",
      "Training MSE: 0.23612\n",
      "-- Epoch 18\n",
      "Training MSE: 0.23498\n",
      "-- Epoch 19\n",
      "Training MSE: 0.23390\n",
      "-- Epoch 20\n",
      "Training MSE: 0.23291\n",
      "test MSE : 0.7063 \n",
      "\n",
      "['user', 'movie']\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.60339\n",
      "-- Epoch 2\n",
      "Training MSE: 0.52638\n",
      "-- Epoch 3\n",
      "Training MSE: 0.49771\n",
      "-- Epoch 4\n",
      "Training MSE: 0.48074\n",
      "-- Epoch 5\n",
      "Training MSE: 0.46937\n",
      "-- Epoch 6\n",
      "Training MSE: 0.46136\n",
      "-- Epoch 7\n",
      "Training MSE: 0.45511\n",
      "-- Epoch 8\n",
      "Training MSE: 0.44999\n",
      "-- Epoch 9\n",
      "Training MSE: 0.44585\n",
      "-- Epoch 10\n",
      "Training MSE: 0.44238\n",
      "-- Epoch 11\n",
      "Training MSE: 0.43930\n",
      "-- Epoch 12\n",
      "Training MSE: 0.43676\n",
      "-- Epoch 13\n",
      "Training MSE: 0.43437\n",
      "-- Epoch 14\n",
      "Training MSE: 0.43227\n",
      "-- Epoch 15\n",
      "Training MSE: 0.43026\n",
      "-- Epoch 16\n",
      "Training MSE: 0.42867\n",
      "-- Epoch 17\n",
      "Training MSE: 0.42713\n",
      "-- Epoch 18\n",
      "Training MSE: 0.42552\n",
      "-- Epoch 19\n",
      "Training MSE: 0.42411\n",
      "-- Epoch 20\n",
      "Training MSE: 0.42273\n",
      "test MSE : 0.9516 \n",
      "\n",
      "['user', 'business']\n",
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.62844\n",
      "-- Epoch 2\n",
      "Training MSE: 0.59429\n",
      "-- Epoch 3\n",
      "Training MSE: 0.57793\n",
      "-- Epoch 4\n",
      "Training MSE: 0.56497\n",
      "-- Epoch 5\n",
      "Training MSE: 0.55418\n",
      "-- Epoch 6\n",
      "Training MSE: 0.54504\n",
      "-- Epoch 7\n",
      "Training MSE: 0.53704\n",
      "-- Epoch 8\n",
      "Training MSE: 0.53015\n",
      "-- Epoch 9\n",
      "Training MSE: 0.52393\n",
      "-- Epoch 10\n",
      "Training MSE: 0.51827\n",
      "-- Epoch 11\n",
      "Training MSE: 0.51314\n",
      "-- Epoch 12\n",
      "Training MSE: 0.50845\n",
      "-- Epoch 13\n",
      "Training MSE: 0.50403\n",
      "-- Epoch 14\n",
      "Training MSE: 0.50005\n",
      "-- Epoch 15\n",
      "Training MSE: 0.49633\n",
      "-- Epoch 16\n",
      "Training MSE: 0.49285\n",
      "-- Epoch 17\n",
      "Training MSE: 0.48952\n",
      "-- Epoch 18\n",
      "Training MSE: 0.48632\n",
      "-- Epoch 19\n",
      "Training MSE: 0.48341\n",
      "-- Epoch 20\n",
      "Training MSE: 0.48060\n",
      "test MSE : 1.0324 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FM\n",
    "# https://github.com/coreylynch/pyFM\n",
    "# 3 mins\n",
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def FM(data, feats, target) :\n",
    "    print(feats)\n",
    "    data = data.astype(str)\n",
    "    train, test = train_test_split(data, test_size = config['test_size'])\n",
    "    train_y = pd.Series(train[target].astype(float)).tolist()\n",
    "    train_x = train[feats].to_dict('records')\n",
    "    test_y = np.array(test[target].astype(float)) # .tolist()\n",
    "    test_x = test[feats].to_dict('records')\n",
    "\n",
    "    v = DictVectorizer()\n",
    "    X = v.fit_transform(train_x).astype('double')\n",
    "    fm = pylibfm.FM(num_factors=10, num_iter=config['n_epoch'], verbose=True, task=\"regression\", initial_learning_rate=0.001, learning_rate_schedule=\"optimal\")\n",
    "    fm.fit(X,train_y)\n",
    "    temp = fm.predict(v.transform(test_x))\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(test_y, temp))\n",
    "    test_y = np.where(test_y > 3, 1, 0)\n",
    "    temp = np.where(temp > 3, 1, 0)\n",
    "    ndcg = ndcg_score(test_y.reshape(1, -1), temp.reshape(1, -1), k=10)\n",
    "    recall = recall_score(test_y.squeeze(), temp.squeeze())\n",
    "    print(\"test MSE : {:.4f}\".format(rmse, 4), '\\n')\n",
    "    \n",
    "    return rmse, ndcg, recall\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)\n",
    "    \n",
    "data_ls = [DoubanBook['user_book'], Movielens['user_movie'], Yelp['user_business']]\n",
    "feats_ls = [['user', 'book', 'rating'], [\"user\", \"movie\", \"rating\"], ['user', 'business', 'rating']]\n",
    "for data, feats in zip(data_ls, feats_ls):\n",
    "    name = feats[1] + 'FM'\n",
    "    rmse_t, ndcg_t, recall_t = FM(data, feats[:-1], feats[-1])\n",
    "    rmse[name] = rmse_t\n",
    "    ndcg_10[name] = ndcg_t\n",
    "    recall_10[name] = recall_t\n",
    "    \n",
    "with open(\"./metrics/rmse.txt\", \"w\") as fp:\n",
    "    json.dump(rmse, fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"w\") as fp:\n",
    "    json.dump(ndcg_10, fp)\n",
    "with open(\"./metrics/recall.txt\", \"w\") as fp:\n",
    "    json.dump(recall_10, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RankFM' from 'rankfm.rankfm' (/home/rita/111/111-2MLG/HW3/rankfm/rankfm/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb 儲存格 11\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# plt.rcParams\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# git_repo = git.Repo('.', search_parent_directories=True)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# git_root = git_repo.git.rev_parse('--show-toplevel')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# %load_ext autoreload\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# %autoreload 2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrankfm\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrankfm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrankfm\u001b[39;00m \u001b[39mimport\u001b[39;00m RankFM\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrankfm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mevaluation\u001b[39;00m \u001b[39mimport\u001b[39;00m hit_rate, reciprocal_rank, discounted_cumulative_gain, precision, recall, diversity\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# repo_root = \"/Users/ericlundquist/Repos/rankfm\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# data_path = os.path.join(repo_root, \"data/examples\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B140.116.52.214/home/rita/111/111-2MLG/HW3/MLG_HW3.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# print(\"\\n\".join([repo_root, data_path]))\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RankFM' from 'rankfm.rankfm' (/home/rita/111/111-2MLG/HW3/rankfm/rankfm/__init__.py)"
     ]
    }
   ],
   "source": [
    "#not yet\n",
    "# BPR-FM\n",
    "# https://github.com/etlundquist/rankfm/blob/master/examples/movielens.ipynb\n",
    "import os, sys, git\n",
    "import numba as nb\n",
    "import warnings\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "# plt.rcParams\n",
    "# git_repo = git.Repo('.', search_parent_directories=True)\n",
    "# git_root = git_repo.git.rev_parse('--show-toplevel')\n",
    "# cython_path = os.path.join(git_root, 'rankfm')\n",
    "\n",
    "# sys.path[0] = git_root\n",
    "# sys.path[1] = cython_path\n",
    "# sys.path[:2]\n",
    "# !cd $git_root && python setup.py build_ext --inplace\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import rankfm\n",
    "from rankfm.rankfm import RankFM\n",
    "from rankfm.evaluation import hit_rate, reciprocal_rank, discounted_cumulative_gain, precision, recall, diversity\n",
    "\n",
    "\n",
    "# repo_root = \"/Users/ericlundquist/Repos/rankfm\"\n",
    "# data_path = os.path.join(repo_root, \"data/examples\")\n",
    "# print(\"\\n\".join([repo_root, data_path]))\n",
    "\n",
    "interactions = Movielens['user_movie']\n",
    "interactions_train, interactions_test = train_test_split(interactions, test_size = config['test_size'])\n",
    "\n",
    "user_features = Movielens['user']\n",
    "item_features = Movielens['movie_genre']\n",
    "\n",
    "item_names = pd.read_csv(os.path.join(data_path, 'ML_1M_ITEM_NAMES.csv'))\n",
    "\n",
    "\n",
    "\n",
    "unique_users = interactions.user_id.nunique()\n",
    "unique_items = interactions.item_id.nunique()\n",
    "\n",
    "print(\"interactions shape: {}\".format(interactions.shape))\n",
    "print(\"interactions unique users: {}\".format(interactions.user_id.nunique()))\n",
    "print(\"interactions unique items: {}\".format(interactions.item_id.nunique()))\n",
    "\n",
    "print(\"user features users:\", interactions.user_id.nunique())\n",
    "print(\"item features items:\", interactions.item_id.nunique())\n",
    "\n",
    "\n",
    "\n",
    "sparsity = 1 - (len(interactions) / (unique_users * unique_items))\n",
    "print(\"interaction matrix sparsity: {}%\".format(round(100 * sparsity, 1)))\n",
    "\n",
    "\n",
    "np.random.seed(1492)\n",
    "interactions['random'] = np.random.random(size=len(interactions))\n",
    "test_pct = 0.25\n",
    "\n",
    "\n",
    "train_mask = interactions['random'] <  (1 - test_pct)\n",
    "valid_mask = interactions['random'] >= (1 - test_pct)\n",
    "\n",
    "interactions_train = interactions[train_mask][['user_id', 'item_id']]\n",
    "interactions_valid = interactions[valid_mask][['user_id', 'item_id']]\n",
    "\n",
    "train_users = np.sort(interactions_train.user_id.unique())\n",
    "valid_users = np.sort(interactions_valid.user_id.unique())\n",
    "cold_start_users = set(valid_users) - set(train_users)\n",
    "\n",
    "train_items = np.sort(interactions_train.item_id.unique())\n",
    "valid_items = np.sort(interactions_valid.item_id.unique())\n",
    "cold_start_items = set(valid_items) - set(train_items)\n",
    "\n",
    "print(\"train shape: {}\".format(interactions_train.shape))\n",
    "print(\"valid shape: {}\".format(interactions_valid.shape))\n",
    "\n",
    "print(\"train users: {}\".format(len(train_users)))\n",
    "print(\"valid users: {}\".format(len(valid_users)))\n",
    "print(\"cold-start users: {}\".format(cold_start_users))\n",
    "\n",
    "print(\"train items: {}\".format(len(train_items)))\n",
    "print(\"valid items: {}\".format(len(valid_items)))\n",
    "print(\"cold-start items: {}\".format(cold_start_items))\n",
    "\n",
    "user_features = user_features[user_features.user_id.isin(train_users)]\n",
    "item_features = item_features[item_features.item_id.isin(train_items)]\n",
    "user_features.shape, item_features.shape\n",
    "\n",
    "model = RankFM(factors=20, loss='warp', max_samples=20, alpha=0.01, sigma=0.1, learning_rate=0.10, learning_schedule='invscaling')\n",
    "model\n",
    "\n",
    "\n",
    "%%time\n",
    "model.fit(interactions_train, epochs=20, verbose=True)\n",
    "\n",
    "valid_scores = model.predict(interactions_valid, cold_start='nan') \n",
    "print(valid_scores.shape)\n",
    "pd.Series(valid_scores).describe()\n",
    "\n",
    "valid_recommendations = model.recommend(valid_users, n_items=10, filter_previous=True, cold_start='nan')\n",
    "valid_recommendations.head()\n",
    "\n",
    "k = 10\n",
    "\n",
    "most_popular = interactions_train.groupby('item_id')['user_id'].count().sort_values(ascending=False)[:k]\n",
    "most_popular\n",
    "\n",
    "test_user_items = interactions_valid.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "test_user_items = {key: val for key, val in test_user_items.items() if key in set(train_users)}\n",
    "\n",
    "base_hrt = np.mean([int(len(set(most_popular.index) & set(val)) > 0)                       for key, val in test_user_items.items()])\n",
    "base_pre = np.mean([len(set(most_popular.index) & set(val)) / len(set(most_popular.index)) for key, val in test_user_items.items()])\n",
    "base_rec = np.mean([len(set(most_popular.index) & set(val)) / len(set(val))                for key, val in test_user_items.items()])\n",
    "\n",
    "print(\"number of test users: {}\".format(len(test_user_items)))\n",
    "print(\"baseline hit rate: {:.3f}\".format(base_hrt))\n",
    "print(\"baseline precision: {:.3f}\".format(base_pre))\n",
    "print(\"baseline recall: {:.3f}\".format(base_rec))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%%time\n",
    "model_hit_rate = hit_rate(model, interactions_valid, k=k)\n",
    "model_reciprocal_rank = reciprocal_rank(model, interactions_valid, k=k)\n",
    "model_dcg = discounted_cumulative_gain(model, interactions_valid, k=k)\n",
    "model_precision = precision(model, interactions_valid, k=k)\n",
    "model_recall = recall(model, interactions_valid, k=k)\n",
    "\n",
    "\n",
    "print(\"hit_rate: {:.3f}\".format(model_hit_rate))\n",
    "print(\"reciprocal_rank: {:.3f}\".format(model_reciprocal_rank))\n",
    "print(\"dcg: {:.3f}\".format(model_dcg, 3))\n",
    "print(\"precision: {:.3f}\".format(model_precision))\n",
    "print(\"recall: {:.3f}\".format(model_recall))\n",
    "\n",
    "recommendation_diversity = diversity(model, interactions_valid, k=k)\n",
    "recommendation_diversity.head(10)\n",
    "\n",
    "top_items = pd.merge(item_names, recommendation_diversity, on='item_id', how='inner')\n",
    "top_items = top_items.set_index('item_id').loc[recommendation_diversity.item_id].reset_index()\n",
    "top_items = top_items[['item_id', 'cnt_users', 'pct_users', 'title', 'genres']]\n",
    "top_items.head(10)\n",
    "\n",
    "coverage = np.mean(recommendation_diversity['cnt_users'] > 0)\n",
    "print(\"percentage of items recommended to at least one user: {:.3f}\".format(coverage))\n",
    "\n",
    "nonzero_users = recommendation_diversity[recommendation_diversity.cnt_users > 0]\n",
    "entropy = -np.sum(nonzero_users['pct_users'] * np.log2(nonzero_users['pct_users']))\n",
    "print(\"entropy value of recommended items: {:.3f}\".format(entropy))\n",
    "\n",
    "N = 50\n",
    "fig, axes = plt.subplots(1, 1, figsize=[16, 4])\n",
    "\n",
    "topN = recommendation_diversity.iloc[:N, :]\n",
    "axes.bar(topN.index.values + 1, topN.pct_users, width=1, edgecolor='black', alpha=0.75)\n",
    "axes.set(xlabel='Item Rank', ylabel='Percentage of Users', title='Percentage of Users Recommended by Item Rank')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "random_user = np.random.choice(interactions_valid.user_id.unique())\n",
    "print(\"random user: {}\".format(random_user))\n",
    "\n",
    "random_user_recs = valid_recommendations.loc[random_user]\n",
    "random_user_recs = item_names[item_names.item_id.isin(random_user_recs)].set_index('item_id').loc[random_user_recs]\n",
    "random_user_recs\n",
    "\n",
    "most_similar_items = model.similar_items(919)\n",
    "most_similar_items = item_names.set_index('item_id').loc[most_similar_items]\n",
    "most_similar_items\n",
    "\n",
    "most_similar_items = model.similar_items(2028)\n",
    "most_similar_items = item_names.set_index('item_id').loc[most_similar_items]\n",
    "most_similar_items\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 NN-based RecSys Methods\n",
    "FNN **IPNN** **OPNN** **PIN** **CCPM** NeuMF **WD** **DeepCross** **NFM** **DeepFM** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN-based model\n",
    "from deepctr_torch.models import PNN # PIN\n",
    "from deepctr_torch.models import CCPM # CCPM\n",
    "\n",
    "from deepctr_torch.models import WDL # WD\n",
    "from deepctr_torch.models import DCN # DeepCross\n",
    "from deepctr_torch.models import NFM # NFM\n",
    "from deepctr_torch.models import DeepFM # DeepFM\n",
    "\n",
    "#recent nn-based approach\n",
    "from deepctr_torch.models import AFM # AFM\n",
    "from deepctr_torch.models import xDeepFM # xDeePFM\n",
    "\n",
    "# new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class nn_based :\n",
    "    def __init__(self, data, features, target, device = 'cuda') : \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        for feat in self.features :\n",
    "            enc = LabelEncoder()\n",
    "            data[feat] = enc.fit_transform(data[feat])\n",
    "        # SparseFeat(name, vocabulary_size, embedding_dim, use_hash, dtype, embedding_name, group_name)\n",
    "        # Dense : Numeric 、 Sparse : Category 、 Sequence : Time Series       \n",
    "        fixed = [SparseFeat(feat, data[feat].nunique()) for feat in self.features]\n",
    "        linear_feats = fixed\n",
    "        dnn_feats = fixed\n",
    "        feature_names = get_feature_names(linear_feats + dnn_feats)\n",
    "\n",
    "        # train test split\n",
    "        self.train, self.test = train_test_split(data, test_size = 0.2)\n",
    "        self.train_data = {name: self.train[name] for name in feature_names}\n",
    "        self.test_data = {name: self.test[name] for name in feature_names}\n",
    "\n",
    "        self.model_dict = {\"IPNN\":PNN(dnn_feats,use_inner=True,use_outter=False,task='regression',device=device),\n",
    "              \"OPNN\":PNN(dnn_feats,use_inner=False,use_outter=True,task='regression',device=device),\n",
    "              \"PNN\":PNN(dnn_feats,use_inner=True,use_outter=True,task='regression',device=device),\n",
    "              \"CCPM\":CCPM(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"WDL\":WDL(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"DCN\":DCN(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"NFM\":NFM(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"DeepFM\":DeepFM(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"AFM\":AFM(linear_feats, dnn_feats, task='regression',device=device),\n",
    "             \"xDeepFM\":xDeepFM(linear_feats, dnn_feats, task='regression',device=device), \n",
    "            #  \"\"\n",
    "             }\n",
    "             \n",
    "    def train_model(self, model, n_epochs = 10):\n",
    "        print(self.features, model, '==================', sep = '\\n')\n",
    "        model = self.model_dict[model]\n",
    "\n",
    "        model.compile('adam', 'mse', metrics = ['mse'])\n",
    "        history = model.fit(self.train_data,self.train[self.target].values,batch_size=256, epochs=n_epochs, verbose=5, validation_split=0.1)\n",
    "        pred_ans = model.predict(self.test_data, batch_size=256)\n",
    "        \n",
    "        rmse = sqrt(mean_squared_error(self.test[self.target].values, pred_ans))\n",
    "        \n",
    "        test_y = np.where(self.test[self.target].values > 3, 1, 0)\n",
    "        pred_ans = np.where(pred_ans > 3, 1, 0)\n",
    "        \n",
    "        ndcg = ndcg_score(test_y.reshape(1, -1), pred_ans.T, k=10)\n",
    "        recall10 = recall_score(test_y.reshape(1, -1).squeeze(), pred_ans.squeeze())\n",
    "        \n",
    "        print(\"test MSE : {:.4f}\".format(rmse, 4))\n",
    "        print(\"test ndcg : {:.4f}\".format(ndcg, 4))\n",
    "        # print(\"test recall10 : {:.4f}\".format(recall10, 4))\n",
    "        \n",
    "        return rmse, ndcg, recall10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user', 'book', 'location']\n",
      "IPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "15s - loss:  0.7737 - mse:  0.7736 - val_mse:  0.4960\n",
      "Epoch 2/20\n",
      "12s - loss:  0.4756 - mse:  0.4756 - val_mse:  0.4877\n",
      "Epoch 3/20\n",
      "12s - loss:  0.4553 - mse:  0.4552 - val_mse:  0.4836\n",
      "Epoch 4/20\n",
      "13s - loss:  0.4413 - mse:  0.4413 - val_mse:  0.4853\n",
      "Epoch 5/20\n",
      "13s - loss:  0.4299 - mse:  0.4299 - val_mse:  0.4906\n",
      "Epoch 6/20\n",
      "12s - loss:  0.4202 - mse:  0.4202 - val_mse:  0.4974\n",
      "Epoch 7/20\n",
      "12s - loss:  0.4104 - mse:  0.4103 - val_mse:  0.5037\n",
      "Epoch 8/20\n",
      "12s - loss:  0.4006 - mse:  0.4005 - val_mse:  0.5103\n",
      "Epoch 9/20\n",
      "13s - loss:  0.3922 - mse:  0.3921 - val_mse:  0.5199\n",
      "Epoch 10/20\n",
      "12s - loss:  0.3853 - mse:  0.3851 - val_mse:  0.5207\n",
      "Epoch 11/20\n",
      "13s - loss:  0.3792 - mse:  0.3790 - val_mse:  0.5339\n",
      "Epoch 12/20\n",
      "12s - loss:  0.3741 - mse:  0.3739 - val_mse:  0.5404\n",
      "Epoch 13/20\n",
      "13s - loss:  0.3696 - mse:  0.3694 - val_mse:  0.5473\n",
      "Epoch 14/20\n",
      "12s - loss:  0.3653 - mse:  0.3651 - val_mse:  0.5464\n",
      "Epoch 15/20\n",
      "12s - loss:  0.3617 - mse:  0.3615 - val_mse:  0.5539\n",
      "Epoch 16/20\n",
      "12s - loss:  0.3586 - mse:  0.3584 - val_mse:  0.5582\n",
      "Epoch 17/20\n",
      "13s - loss:  0.3552 - mse:  0.3550 - val_mse:  0.5689\n",
      "Epoch 18/20\n",
      "13s - loss:  0.3525 - mse:  0.3522 - val_mse:  0.5818\n",
      "Epoch 19/20\n",
      "12s - loss:  0.3499 - mse:  0.3496 - val_mse:  0.5838\n",
      "Epoch 20/20\n",
      "13s - loss:  0.3470 - mse:  0.3467 - val_mse:  0.5942\n",
      "test MSE : 0.7714\n",
      "test ndcg : 0.7702\n",
      "['user', 'book', 'location']\n",
      "OPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "13s - loss:  0.7853 - mse:  0.7853 - val_mse:  0.4959\n",
      "Epoch 2/20\n",
      "15s - loss:  0.4738 - mse:  0.4738 - val_mse:  0.4836\n",
      "Epoch 3/20\n",
      "13s - loss:  0.4533 - mse:  0.4533 - val_mse:  0.4904\n",
      "Epoch 4/20\n",
      "14s - loss:  0.4409 - mse:  0.4409 - val_mse:  0.4845\n",
      "Epoch 5/20\n",
      "15s - loss:  0.4293 - mse:  0.4292 - val_mse:  0.4902\n",
      "Epoch 6/20\n",
      "13s - loss:  0.4174 - mse:  0.4173 - val_mse:  0.4976\n",
      "Epoch 7/20\n",
      "13s - loss:  0.4066 - mse:  0.4066 - val_mse:  0.4994\n",
      "Epoch 8/20\n",
      "13s - loss:  0.3983 - mse:  0.3982 - val_mse:  0.5044\n",
      "Epoch 9/20\n",
      "14s - loss:  0.3917 - mse:  0.3916 - val_mse:  0.5107\n",
      "Epoch 10/20\n",
      "13s - loss:  0.3861 - mse:  0.3860 - val_mse:  0.5182\n",
      "Epoch 11/20\n",
      "13s - loss:  0.3807 - mse:  0.3805 - val_mse:  0.5225\n",
      "Epoch 12/20\n",
      "15s - loss:  0.3748 - mse:  0.3746 - val_mse:  0.5305\n",
      "Epoch 13/20\n",
      "14s - loss:  0.3684 - mse:  0.3683 - val_mse:  0.5322\n",
      "Epoch 14/20\n",
      "13s - loss:  0.3633 - mse:  0.3631 - val_mse:  0.5508\n",
      "Epoch 15/20\n",
      "14s - loss:  0.3590 - mse:  0.3588 - val_mse:  0.5491\n",
      "Epoch 16/20\n",
      "13s - loss:  0.3554 - mse:  0.3552 - val_mse:  0.5476\n",
      "Epoch 17/20\n",
      "14s - loss:  0.3522 - mse:  0.3519 - val_mse:  0.5580\n",
      "Epoch 18/20\n",
      "13s - loss:  0.3499 - mse:  0.3496 - val_mse:  0.5617\n",
      "Epoch 19/20\n",
      "13s - loss:  0.3474 - mse:  0.3471 - val_mse:  0.5771\n",
      "Epoch 20/20\n",
      "13s - loss:  0.3454 - mse:  0.3451 - val_mse:  0.5742\n",
      "test MSE : 0.7580\n",
      "test ndcg : 0.7716\n",
      "['user', 'book', 'location']\n",
      "PNN\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "13s - loss:  0.7939 - mse:  0.7939 - val_mse:  0.4965\n",
      "Epoch 2/20\n",
      "13s - loss:  0.4790 - mse:  0.4790 - val_mse:  0.4899\n",
      "Epoch 3/20\n",
      "13s - loss:  0.4618 - mse:  0.4618 - val_mse:  0.4803\n",
      "Epoch 4/20\n",
      "15s - loss:  0.4463 - mse:  0.4463 - val_mse:  0.4813\n",
      "Epoch 5/20\n",
      "14s - loss:  0.4354 - mse:  0.4353 - val_mse:  0.4828\n",
      "Epoch 6/20\n",
      "14s - loss:  0.4237 - mse:  0.4237 - val_mse:  0.4929\n",
      "Epoch 7/20\n",
      "14s - loss:  0.4105 - mse:  0.4105 - val_mse:  0.4942\n",
      "Epoch 8/20\n",
      "13s - loss:  0.3989 - mse:  0.3988 - val_mse:  0.5016\n",
      "Epoch 9/20\n",
      "13s - loss:  0.3890 - mse:  0.3889 - val_mse:  0.5082\n",
      "Epoch 10/20\n",
      "14s - loss:  0.3812 - mse:  0.3811 - val_mse:  0.5189\n",
      "Epoch 11/20\n",
      "13s - loss:  0.3754 - mse:  0.3753 - val_mse:  0.5302\n",
      "Epoch 12/20\n",
      "13s - loss:  0.3704 - mse:  0.3702 - val_mse:  0.5282\n",
      "Epoch 13/20\n",
      "14s - loss:  0.3664 - mse:  0.3663 - val_mse:  0.5319\n",
      "Epoch 14/20\n",
      "15s - loss:  0.3624 - mse:  0.3622 - val_mse:  0.5327\n",
      "Epoch 15/20\n",
      "13s - loss:  0.3596 - mse:  0.3594 - val_mse:  0.5444\n",
      "Epoch 16/20\n",
      "13s - loss:  0.3564 - mse:  0.3562 - val_mse:  0.5466\n",
      "Epoch 17/20\n",
      "14s - loss:  0.3530 - mse:  0.3528 - val_mse:  0.5586\n",
      "Epoch 18/20\n",
      "14s - loss:  0.3498 - mse:  0.3495 - val_mse:  0.5630\n",
      "Epoch 19/20\n",
      "14s - loss:  0.3471 - mse:  0.3469 - val_mse:  0.5665\n",
      "Epoch 20/20\n",
      "15s - loss:  0.3445 - mse:  0.3442 - val_mse:  0.5766\n",
      "test MSE : 0.7598\n",
      "test ndcg : 0.7732\n",
      "['user', 'book', 'location']\n",
      "CCPM\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "21s - loss:  0.7788 - mse:  0.7788 - val_mse:  0.4968\n",
      "Epoch 2/20\n",
      "18s - loss:  0.4769 - mse:  0.4769 - val_mse:  0.4900\n",
      "Epoch 3/20\n",
      "17s - loss:  0.4668 - mse:  0.4668 - val_mse:  0.4911\n",
      "Epoch 4/20\n",
      "17s - loss:  0.4620 - mse:  0.4620 - val_mse:  0.4888\n",
      "Epoch 5/20\n",
      "20s - loss:  0.4583 - mse:  0.4582 - val_mse:  0.4870\n",
      "Epoch 6/20\n",
      "20s - loss:  0.4548 - mse:  0.4547 - val_mse:  0.4868\n",
      "Epoch 7/20\n",
      "17s - loss:  0.4512 - mse:  0.4511 - val_mse:  0.4880\n",
      "Epoch 8/20\n",
      "20s - loss:  0.4465 - mse:  0.4464 - val_mse:  0.4883\n",
      "Epoch 9/20\n",
      "17s - loss:  0.4401 - mse:  0.4400 - val_mse:  0.4885\n",
      "Epoch 10/20\n",
      "18s - loss:  0.4308 - mse:  0.4306 - val_mse:  0.4867\n",
      "Epoch 11/20\n",
      "18s - loss:  0.4201 - mse:  0.4200 - val_mse:  0.4913\n",
      "Epoch 12/20\n",
      "18s - loss:  0.4099 - mse:  0.4097 - val_mse:  0.4956\n",
      "Epoch 13/20\n",
      "17s - loss:  0.3997 - mse:  0.3995 - val_mse:  0.4988\n",
      "Epoch 14/20\n",
      "19s - loss:  0.3904 - mse:  0.3902 - val_mse:  0.5075\n",
      "Epoch 15/20\n",
      "18s - loss:  0.3818 - mse:  0.3816 - val_mse:  0.5157\n",
      "Epoch 16/20\n",
      "17s - loss:  0.3739 - mse:  0.3736 - val_mse:  0.5211\n",
      "Epoch 17/20\n",
      "18s - loss:  0.3666 - mse:  0.3663 - val_mse:  0.5237\n",
      "Epoch 18/20\n",
      "18s - loss:  0.3603 - mse:  0.3600 - val_mse:  0.5273\n",
      "Epoch 19/20\n",
      "19s - loss:  0.3541 - mse:  0.3538 - val_mse:  0.5364\n",
      "Epoch 20/20\n",
      "17s - loss:  0.3489 - mse:  0.3486 - val_mse:  0.5422\n",
      "test MSE : 0.7356\n",
      "test ndcg : 0.7721\n",
      "['user', 'book', 'location']\n",
      "WDL\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "14s - loss:  0.6826 - mse:  0.6826 - val_mse:  0.5034\n",
      "Epoch 2/20\n",
      "14s - loss:  0.4801 - mse:  0.4801 - val_mse:  0.4929\n",
      "Epoch 3/20\n",
      "15s - loss:  0.4717 - mse:  0.4717 - val_mse:  0.4903\n",
      "Epoch 4/20\n",
      "16s - loss:  0.4668 - mse:  0.4668 - val_mse:  0.4899\n",
      "Epoch 5/20\n",
      "15s - loss:  0.4637 - mse:  0.4637 - val_mse:  0.4997\n",
      "Epoch 6/20\n",
      "16s - loss:  0.4614 - mse:  0.4613 - val_mse:  0.4961\n",
      "Epoch 7/20\n",
      "15s - loss:  0.4592 - mse:  0.4591 - val_mse:  0.4887\n",
      "Epoch 8/20\n",
      "15s - loss:  0.4568 - mse:  0.4567 - val_mse:  0.4893\n",
      "Epoch 9/20\n",
      "15s - loss:  0.4536 - mse:  0.4535 - val_mse:  0.4888\n",
      "Epoch 10/20\n",
      "16s - loss:  0.4508 - mse:  0.4506 - val_mse:  0.4843\n",
      "Epoch 11/20\n",
      "15s - loss:  0.4447 - mse:  0.4445 - val_mse:  0.4832\n",
      "Epoch 12/20\n",
      "15s - loss:  0.4370 - mse:  0.4369 - val_mse:  0.4827\n",
      "Epoch 13/20\n",
      "15s - loss:  0.4302 - mse:  0.4300 - val_mse:  0.4858\n",
      "Epoch 14/20\n",
      "15s - loss:  0.4234 - mse:  0.4232 - val_mse:  0.4877\n",
      "Epoch 15/20\n",
      "15s - loss:  0.4176 - mse:  0.4174 - val_mse:  0.4925\n",
      "Epoch 16/20\n",
      "16s - loss:  0.4121 - mse:  0.4119 - val_mse:  0.4951\n",
      "Epoch 17/20\n",
      "18s - loss:  0.4069 - mse:  0.4067 - val_mse:  0.4991\n",
      "Epoch 18/20\n",
      "18s - loss:  0.4021 - mse:  0.4019 - val_mse:  0.5028\n",
      "Epoch 19/20\n",
      "18s - loss:  0.3975 - mse:  0.3973 - val_mse:  0.5049\n",
      "Epoch 20/20\n",
      "15s - loss:  0.3928 - mse:  0.3925 - val_mse:  0.5127\n",
      "test MSE : 0.7139\n",
      "test ndcg : 0.7715\n",
      "['user', 'book', 'location']\n",
      "DCN\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "18s - loss:  0.7912 - mse:  0.7911 - val_mse:  0.4985\n",
      "Epoch 2/20\n",
      "18s - loss:  0.4800 - mse:  0.4800 - val_mse:  0.4924\n",
      "Epoch 3/20\n",
      "18s - loss:  0.4700 - mse:  0.4699 - val_mse:  0.4902\n",
      "Epoch 4/20\n",
      "18s - loss:  0.4642 - mse:  0.4641 - val_mse:  0.4877\n",
      "Epoch 5/20\n",
      "18s - loss:  0.4579 - mse:  0.4578 - val_mse:  0.4845\n",
      "Epoch 6/20\n",
      "18s - loss:  0.4501 - mse:  0.4501 - val_mse:  0.4817\n",
      "Epoch 7/20\n",
      "19s - loss:  0.4421 - mse:  0.4420 - val_mse:  0.4809\n",
      "Epoch 8/20\n",
      "18s - loss:  0.4352 - mse:  0.4351 - val_mse:  0.4818\n",
      "Epoch 9/20\n",
      "19s - loss:  0.4284 - mse:  0.4283 - val_mse:  0.4854\n",
      "Epoch 10/20\n",
      "18s - loss:  0.4228 - mse:  0.4227 - val_mse:  0.4880\n",
      "Epoch 11/20\n",
      "19s - loss:  0.4181 - mse:  0.4179 - val_mse:  0.4918\n",
      "Epoch 12/20\n",
      "18s - loss:  0.4130 - mse:  0.4129 - val_mse:  0.4967\n",
      "Epoch 13/20\n",
      "18s - loss:  0.4071 - mse:  0.4069 - val_mse:  0.4989\n",
      "Epoch 14/20\n",
      "18s - loss:  0.4005 - mse:  0.4003 - val_mse:  0.5054\n",
      "Epoch 15/20\n",
      "18s - loss:  0.3940 - mse:  0.3938 - val_mse:  0.5084\n",
      "Epoch 16/20\n",
      "18s - loss:  0.3884 - mse:  0.3881 - val_mse:  0.5157\n",
      "Epoch 17/20\n",
      "18s - loss:  0.3832 - mse:  0.3830 - val_mse:  0.5218\n",
      "Epoch 18/20\n",
      "19s - loss:  0.3782 - mse:  0.3780 - val_mse:  0.5257\n",
      "Epoch 19/20\n",
      "18s - loss:  0.3733 - mse:  0.3730 - val_mse:  0.5311\n",
      "Epoch 20/20\n",
      "18s - loss:  0.3688 - mse:  0.3685 - val_mse:  0.5342\n",
      "test MSE : 0.7320\n",
      "test ndcg : 0.7700\n",
      "['user', 'book', 'location']\n",
      "NFM\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "15s - loss:  0.7199 - mse:  0.7199 - val_mse:  0.4963\n",
      "Epoch 2/20\n",
      "16s - loss:  0.4684 - mse:  0.4684 - val_mse:  0.4896\n",
      "Epoch 3/20\n",
      "16s - loss:  0.4462 - mse:  0.4461 - val_mse:  0.4885\n",
      "Epoch 4/20\n",
      "16s - loss:  0.4309 - mse:  0.4309 - val_mse:  0.4960\n",
      "Epoch 5/20\n",
      "16s - loss:  0.4185 - mse:  0.4184 - val_mse:  0.4996\n",
      "Epoch 6/20\n",
      "16s - loss:  0.4077 - mse:  0.4077 - val_mse:  0.5051\n",
      "Epoch 7/20\n",
      "16s - loss:  0.3981 - mse:  0.3980 - val_mse:  0.5182\n",
      "Epoch 8/20\n",
      "16s - loss:  0.3900 - mse:  0.3899 - val_mse:  0.5194\n",
      "Epoch 9/20\n",
      "16s - loss:  0.3827 - mse:  0.3826 - val_mse:  0.5218\n",
      "Epoch 10/20\n",
      "16s - loss:  0.3764 - mse:  0.3762 - val_mse:  0.5301\n",
      "Epoch 11/20\n",
      "16s - loss:  0.3706 - mse:  0.3704 - val_mse:  0.5403\n",
      "Epoch 12/20\n",
      "16s - loss:  0.3654 - mse:  0.3652 - val_mse:  0.5397\n",
      "Epoch 13/20\n",
      "15s - loss:  0.3606 - mse:  0.3604 - val_mse:  0.5469\n",
      "Epoch 14/20\n",
      "16s - loss:  0.3564 - mse:  0.3561 - val_mse:  0.5455\n",
      "Epoch 15/20\n",
      "15s - loss:  0.3525 - mse:  0.3522 - val_mse:  0.5507\n",
      "Epoch 16/20\n",
      "16s - loss:  0.3492 - mse:  0.3490 - val_mse:  0.5577\n",
      "Epoch 17/20\n",
      "16s - loss:  0.3457 - mse:  0.3454 - val_mse:  0.5603\n",
      "Epoch 18/20\n",
      "15s - loss:  0.3431 - mse:  0.3428 - val_mse:  0.5692\n",
      "Epoch 19/20\n",
      "16s - loss:  0.3400 - mse:  0.3396 - val_mse:  0.5657\n",
      "Epoch 20/20\n",
      "16s - loss:  0.3374 - mse:  0.3371 - val_mse:  0.5705\n",
      "test MSE : 0.7566\n",
      "test ndcg : 0.7742\n",
      "['user', 'book', 'location']\n",
      "DeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "15s - loss:  0.6826 - mse:  0.6826 - val_mse:  0.4986\n",
      "Epoch 2/20\n",
      "16s - loss:  0.4811 - mse:  0.4810 - val_mse:  0.4960\n",
      "Epoch 3/20\n",
      "16s - loss:  0.4725 - mse:  0.4725 - val_mse:  0.4924\n",
      "Epoch 4/20\n",
      "16s - loss:  0.4682 - mse:  0.4682 - val_mse:  0.4947\n",
      "Epoch 5/20\n",
      "16s - loss:  0.4647 - mse:  0.4647 - val_mse:  0.4924\n",
      "Epoch 6/20\n",
      "16s - loss:  0.4618 - mse:  0.4618 - val_mse:  0.4934\n",
      "Epoch 7/20\n",
      "16s - loss:  0.4582 - mse:  0.4581 - val_mse:  0.4850\n",
      "Epoch 8/20\n",
      "16s - loss:  0.4490 - mse:  0.4489 - val_mse:  0.4835\n",
      "Epoch 9/20\n",
      "16s - loss:  0.4419 - mse:  0.4418 - val_mse:  0.4852\n",
      "Epoch 10/20\n",
      "16s - loss:  0.4363 - mse:  0.4361 - val_mse:  0.4841\n",
      "Epoch 11/20\n",
      "16s - loss:  0.4297 - mse:  0.4295 - val_mse:  0.4967\n",
      "Epoch 12/20\n",
      "17s - loss:  0.4216 - mse:  0.4214 - val_mse:  0.4875\n",
      "Epoch 13/20\n",
      "16s - loss:  0.4118 - mse:  0.4116 - val_mse:  0.4925\n",
      "Epoch 14/20\n",
      "16s - loss:  0.4013 - mse:  0.4011 - val_mse:  0.4985\n",
      "Epoch 15/20\n",
      "16s - loss:  0.3904 - mse:  0.3902 - val_mse:  0.5123\n",
      "Epoch 16/20\n",
      "16s - loss:  0.3815 - mse:  0.3813 - val_mse:  0.5168\n",
      "Epoch 17/20\n",
      "16s - loss:  0.3748 - mse:  0.3745 - val_mse:  0.5202\n",
      "Epoch 18/20\n",
      "18s - loss:  0.3691 - mse:  0.3688 - val_mse:  0.5278\n",
      "Epoch 19/20\n",
      "16s - loss:  0.3642 - mse:  0.3639 - val_mse:  0.5297\n",
      "Epoch 20/20\n",
      "16s - loss:  0.3591 - mse:  0.3588 - val_mse:  0.5374\n",
      "test MSE : 0.7327\n",
      "test ndcg : 0.7745\n",
      "['user', 'book', 'location']\n",
      "AFM\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "17s - loss:  3.8939 - mse:  3.8935 - val_mse:  0.7889\n",
      "Epoch 2/20\n",
      "15s - loss:  0.6491 - mse:  0.6490 - val_mse:  0.6036\n",
      "Epoch 3/20\n",
      "16s - loss:  0.5452 - mse:  0.5451 - val_mse:  0.5491\n",
      "Epoch 4/20\n",
      "15s - loss:  0.5045 - mse:  0.5043 - val_mse:  0.5236\n",
      "Epoch 5/20\n",
      "16s - loss:  0.4789 - mse:  0.4787 - val_mse:  0.5120\n",
      "Epoch 6/20\n",
      "15s - loss:  0.4604 - mse:  0.4601 - val_mse:  0.5107\n",
      "Epoch 7/20\n",
      "15s - loss:  0.4474 - mse:  0.4472 - val_mse:  0.5107\n",
      "Epoch 8/20\n",
      "15s - loss:  0.4379 - mse:  0.4376 - val_mse:  0.5119\n",
      "Epoch 9/20\n",
      "15s - loss:  0.4300 - mse:  0.4297 - val_mse:  0.5133\n",
      "Epoch 10/20\n",
      "16s - loss:  0.4231 - mse:  0.4228 - val_mse:  0.5161\n",
      "Epoch 11/20\n",
      "15s - loss:  0.4168 - mse:  0.4165 - val_mse:  0.5196\n",
      "Epoch 12/20\n",
      "16s - loss:  0.4111 - mse:  0.4107 - val_mse:  0.5218\n",
      "Epoch 13/20\n",
      "15s - loss:  0.4065 - mse:  0.4061 - val_mse:  0.5235\n",
      "Epoch 14/20\n",
      "16s - loss:  0.4022 - mse:  0.4018 - val_mse:  0.5280\n",
      "Epoch 15/20\n",
      "16s - loss:  0.3983 - mse:  0.3979 - val_mse:  0.5297\n",
      "Epoch 16/20\n",
      "15s - loss:  0.3948 - mse:  0.3944 - val_mse:  0.5318\n",
      "Epoch 17/20\n",
      "16s - loss:  0.3916 - mse:  0.3911 - val_mse:  0.5339\n",
      "Epoch 18/20\n",
      "15s - loss:  0.3885 - mse:  0.3881 - val_mse:  0.5374\n",
      "Epoch 19/20\n",
      "15s - loss:  0.3858 - mse:  0.3854 - val_mse:  0.5399\n",
      "Epoch 20/20\n",
      "15s - loss:  0.3833 - mse:  0.3828 - val_mse:  0.5432\n",
      "test MSE : 0.7360\n",
      "test ndcg : 0.7696\n",
      "['user', 'book', 'location']\n",
      "xDeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 568006 samples, validate on 63112 samples, 2219 steps per epoch\n",
      "Epoch 1/20\n",
      "20s - loss:  0.6147 - mse:  0.6147 - val_mse:  0.5000\n",
      "Epoch 2/20\n",
      "20s - loss:  0.4797 - mse:  0.4797 - val_mse:  0.4901\n",
      "Epoch 3/20\n",
      "20s - loss:  0.4686 - mse:  0.4686 - val_mse:  0.4880\n",
      "Epoch 4/20\n",
      "20s - loss:  0.4619 - mse:  0.4618 - val_mse:  0.4874\n",
      "Epoch 5/20\n",
      "20s - loss:  0.4561 - mse:  0.4561 - val_mse:  0.4884\n",
      "Epoch 6/20\n",
      "20s - loss:  0.4515 - mse:  0.4514 - val_mse:  0.4875\n",
      "Epoch 7/20\n",
      "20s - loss:  0.4455 - mse:  0.4454 - val_mse:  0.4870\n",
      "Epoch 8/20\n",
      "20s - loss:  0.4367 - mse:  0.4366 - val_mse:  0.4853\n",
      "Epoch 9/20\n",
      "20s - loss:  0.4255 - mse:  0.4254 - val_mse:  0.4946\n",
      "Epoch 10/20\n",
      "21s - loss:  0.4128 - mse:  0.4126 - val_mse:  0.4982\n",
      "Epoch 11/20\n",
      "20s - loss:  0.4000 - mse:  0.3999 - val_mse:  0.5043\n",
      "Epoch 12/20\n",
      "20s - loss:  0.3888 - mse:  0.3886 - val_mse:  0.5250\n",
      "Epoch 13/20\n",
      "20s - loss:  0.3786 - mse:  0.3784 - val_mse:  0.5279\n",
      "Epoch 14/20\n",
      "20s - loss:  0.3693 - mse:  0.3691 - val_mse:  0.5321\n",
      "Epoch 15/20\n",
      "20s - loss:  0.3615 - mse:  0.3612 - val_mse:  0.5372\n",
      "Epoch 16/20\n",
      "20s - loss:  0.3545 - mse:  0.3543 - val_mse:  0.5493\n",
      "Epoch 17/20\n",
      "20s - loss:  0.3482 - mse:  0.3480 - val_mse:  0.5527\n",
      "Epoch 18/20\n",
      "20s - loss:  0.3431 - mse:  0.3428 - val_mse:  0.5585\n",
      "Epoch 19/20\n",
      "20s - loss:  0.3383 - mse:  0.3380 - val_mse:  0.5589\n",
      "Epoch 20/20\n",
      "20s - loss:  0.3345 - mse:  0.3342 - val_mse:  0.5681\n",
      "test MSE : 0.7523\n",
      "test ndcg : 0.7779\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "IPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.5112 - mse:  2.5064 - val_mse:  0.8826\n",
      "Epoch 2/20\n",
      "1s - loss:  0.7083 - mse:  0.7091 - val_mse:  0.9250\n",
      "Epoch 3/20\n",
      "1s - loss:  0.5114 - mse:  0.5119 - val_mse:  0.9849\n",
      "Epoch 4/20\n",
      "1s - loss:  0.4422 - mse:  0.4428 - val_mse:  1.0171\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4119 - mse:  0.4119 - val_mse:  1.0361\n",
      "Epoch 6/20\n",
      "1s - loss:  0.3935 - mse:  0.3941 - val_mse:  1.0413\n",
      "Epoch 7/20\n",
      "1s - loss:  0.3807 - mse:  0.3813 - val_mse:  1.0585\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3716 - mse:  0.3719 - val_mse:  1.0700\n",
      "Epoch 9/20\n",
      "1s - loss:  0.3637 - mse:  0.3636 - val_mse:  1.0687\n",
      "Epoch 10/20\n",
      "1s - loss:  0.3563 - mse:  0.3561 - val_mse:  1.0724\n",
      "Epoch 11/20\n",
      "1s - loss:  0.3477 - mse:  0.3479 - val_mse:  1.0864\n",
      "Epoch 12/20\n",
      "1s - loss:  0.3385 - mse:  0.3386 - val_mse:  1.0813\n",
      "Epoch 13/20\n",
      "1s - loss:  0.3250 - mse:  0.3255 - val_mse:  1.0962\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3080 - mse:  0.3082 - val_mse:  1.1083\n",
      "Epoch 15/20\n",
      "1s - loss:  0.2860 - mse:  0.2863 - val_mse:  1.1354\n",
      "Epoch 16/20\n",
      "1s - loss:  0.2565 - mse:  0.2568 - val_mse:  1.1713\n",
      "Epoch 17/20\n",
      "1s - loss:  0.2225 - mse:  0.2226 - val_mse:  1.1970\n",
      "Epoch 18/20\n",
      "1s - loss:  0.1876 - mse:  0.1879 - val_mse:  1.2387\n",
      "Epoch 19/20\n",
      "1s - loss:  0.1560 - mse:  0.1562 - val_mse:  1.2529\n",
      "Epoch 20/20\n",
      "1s - loss:  0.1285 - mse:  0.1285 - val_mse:  1.2790\n",
      "test MSE : 1.1151\n",
      "test ndcg : 0.6390\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "OPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "1s - loss:  2.6501 - mse:  2.6451 - val_mse:  0.8844\n",
      "Epoch 2/20\n",
      "1s - loss:  0.7114 - mse:  0.7117 - val_mse:  0.9194\n",
      "Epoch 3/20\n",
      "1s - loss:  0.5114 - mse:  0.5118 - val_mse:  0.9791\n",
      "Epoch 4/20\n",
      "1s - loss:  0.4434 - mse:  0.4435 - val_mse:  1.0273\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4121 - mse:  0.4124 - val_mse:  1.0329\n",
      "Epoch 6/20\n",
      "1s - loss:  0.3953 - mse:  0.3958 - val_mse:  1.0445\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3830 - mse:  0.3834 - val_mse:  1.0677\n",
      "Epoch 8/20\n",
      "1s - loss:  0.3749 - mse:  0.3748 - val_mse:  1.0639\n",
      "Epoch 9/20\n",
      "1s - loss:  0.3690 - mse:  0.3688 - val_mse:  1.0773\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3641 - mse:  0.3640 - val_mse:  1.0755\n",
      "Epoch 11/20\n",
      "1s - loss:  0.3600 - mse:  0.3601 - val_mse:  1.0885\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3559 - mse:  0.3557 - val_mse:  1.0785\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3510 - mse:  0.3512 - val_mse:  1.0794\n",
      "Epoch 14/20\n",
      "1s - loss:  0.3458 - mse:  0.3455 - val_mse:  1.0864\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3395 - mse:  0.3395 - val_mse:  1.0832\n",
      "Epoch 16/20\n",
      "1s - loss:  0.3324 - mse:  0.3323 - val_mse:  1.1041\n",
      "Epoch 17/20\n",
      "1s - loss:  0.3232 - mse:  0.3234 - val_mse:  1.0988\n",
      "Epoch 18/20\n",
      "1s - loss:  0.3113 - mse:  0.3113 - val_mse:  1.1224\n",
      "Epoch 19/20\n",
      "2s - loss:  0.2951 - mse:  0.2951 - val_mse:  1.1251\n",
      "Epoch 20/20\n",
      "1s - loss:  0.2764 - mse:  0.2765 - val_mse:  1.1412\n",
      "test MSE : 1.0561\n",
      "test ndcg : 0.6347\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "PNN\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.4678 - mse:  2.4634 - val_mse:  0.8847\n",
      "Epoch 2/20\n",
      "2s - loss:  0.7053 - mse:  0.7055 - val_mse:  0.9244\n",
      "Epoch 3/20\n",
      "2s - loss:  0.5084 - mse:  0.5089 - val_mse:  0.9755\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4411 - mse:  0.4411 - val_mse:  1.0133\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4077 - mse:  0.4078 - val_mse:  1.0238\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3869 - mse:  0.3865 - val_mse:  1.0349\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3714 - mse:  0.3712 - val_mse:  1.0525\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3601 - mse:  0.3602 - val_mse:  1.0646\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3497 - mse:  0.3497 - val_mse:  1.0899\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3417 - mse:  0.3419 - val_mse:  1.0863\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3329 - mse:  0.3331 - val_mse:  1.1008\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3215 - mse:  0.3218 - val_mse:  1.1148\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3064 - mse:  0.3066 - val_mse:  1.1386\n",
      "Epoch 14/20\n",
      "2s - loss:  0.2846 - mse:  0.2845 - val_mse:  1.1613\n",
      "Epoch 15/20\n",
      "2s - loss:  0.2580 - mse:  0.2581 - val_mse:  1.1811\n",
      "Epoch 16/20\n",
      "2s - loss:  0.2272 - mse:  0.2270 - val_mse:  1.2120\n",
      "Epoch 17/20\n",
      "2s - loss:  0.1947 - mse:  0.1947 - val_mse:  1.2304\n",
      "Epoch 18/20\n",
      "2s - loss:  0.1665 - mse:  0.1667 - val_mse:  1.2528\n",
      "Epoch 19/20\n",
      "2s - loss:  0.1418 - mse:  0.1417 - val_mse:  1.2771\n",
      "Epoch 20/20\n",
      "2s - loss:  0.1212 - mse:  0.1211 - val_mse:  1.3051\n",
      "test MSE : 1.1223\n",
      "test ndcg : 0.6344\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "CCPM\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.1427 - mse:  2.1397 - val_mse:  0.9886\n",
      "Epoch 2/20\n",
      "2s - loss:  0.8291 - mse:  0.8293 - val_mse:  0.8613\n",
      "Epoch 3/20\n",
      "2s - loss:  0.6092 - mse:  0.6088 - val_mse:  0.9437\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4747 - mse:  0.4743 - val_mse:  0.9866\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4156 - mse:  0.4156 - val_mse:  1.0194\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3891 - mse:  0.3892 - val_mse:  1.0349\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3737 - mse:  0.3734 - val_mse:  1.0492\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3633 - mse:  0.3638 - val_mse:  1.0556\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3572 - mse:  0.3575 - val_mse:  1.0705\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3516 - mse:  0.3519 - val_mse:  1.0769\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3469 - mse:  0.3470 - val_mse:  1.0819\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3425 - mse:  0.3424 - val_mse:  1.0770\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3385 - mse:  0.3384 - val_mse:  1.0941\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3343 - mse:  0.3346 - val_mse:  1.0980\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3297 - mse:  0.3301 - val_mse:  1.1129\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3236 - mse:  0.3237 - val_mse:  1.1136\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3173 - mse:  0.3175 - val_mse:  1.1010\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3092 - mse:  0.3091 - val_mse:  1.1102\n",
      "Epoch 19/20\n",
      "2s - loss:  0.2999 - mse:  0.3003 - val_mse:  1.1166\n",
      "Epoch 20/20\n",
      "2s - loss:  0.2870 - mse:  0.2869 - val_mse:  1.1345\n",
      "test MSE : 1.0622\n",
      "test ndcg : 0.6287\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "WDL\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.1664 - mse:  2.1631 - val_mse:  0.8816\n",
      "Epoch 2/20\n",
      "2s - loss:  0.6975 - mse:  0.6984 - val_mse:  0.9245\n",
      "Epoch 3/20\n",
      "2s - loss:  0.5081 - mse:  0.5080 - val_mse:  0.9809\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4437 - mse:  0.4442 - val_mse:  1.0191\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4136 - mse:  0.4141 - val_mse:  1.0290\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3969 - mse:  0.3970 - val_mse:  1.0585\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3863 - mse:  0.3864 - val_mse:  1.0569\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3783 - mse:  0.3785 - val_mse:  1.0753\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3721 - mse:  0.3724 - val_mse:  1.0775\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3678 - mse:  0.3677 - val_mse:  1.0685\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3637 - mse:  0.3639 - val_mse:  1.0783\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3602 - mse:  0.3601 - val_mse:  1.0884\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3576 - mse:  0.3578 - val_mse:  1.0806\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3553 - mse:  0.3550 - val_mse:  1.0830\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3532 - mse:  0.3534 - val_mse:  1.0837\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3518 - mse:  0.3520 - val_mse:  1.0886\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3493 - mse:  0.3490 - val_mse:  1.0966\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3471 - mse:  0.3472 - val_mse:  1.0991\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3451 - mse:  0.3452 - val_mse:  1.0961\n",
      "Epoch 20/20\n",
      "2s - loss:  0.3445 - mse:  0.3443 - val_mse:  1.0982\n",
      "test MSE : 1.0387\n",
      "test ndcg : 0.6488\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "DCN\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.2266 - mse:  2.2227 - val_mse:  0.8766\n",
      "Epoch 2/20\n",
      "2s - loss:  0.7018 - mse:  0.7016 - val_mse:  0.9241\n",
      "Epoch 3/20\n",
      "2s - loss:  0.5090 - mse:  0.5086 - val_mse:  0.9817\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4431 - mse:  0.4432 - val_mse:  1.0149\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4134 - mse:  0.4140 - val_mse:  1.0349\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3962 - mse:  0.3961 - val_mse:  1.0545\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3847 - mse:  0.3849 - val_mse:  1.0731\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3770 - mse:  0.3769 - val_mse:  1.0599\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3716 - mse:  0.3715 - val_mse:  1.0690\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3668 - mse:  0.3666 - val_mse:  1.0689\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3623 - mse:  0.3619 - val_mse:  1.0845\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3592 - mse:  0.3591 - val_mse:  1.0804\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3562 - mse:  0.3568 - val_mse:  1.0842\n",
      "Epoch 14/20\n",
      "3s - loss:  0.3531 - mse:  0.3535 - val_mse:  1.0758\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3508 - mse:  0.3509 - val_mse:  1.0881\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3486 - mse:  0.3483 - val_mse:  1.1172\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3471 - mse:  0.3470 - val_mse:  1.0890\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3451 - mse:  0.3451 - val_mse:  1.0991\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3430 - mse:  0.3430 - val_mse:  1.1053\n",
      "Epoch 20/20\n",
      "2s - loss:  0.3412 - mse:  0.3413 - val_mse:  1.0957\n",
      "test MSE : 1.0405\n",
      "test ndcg : 0.6296\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "NFM\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.2444 - mse:  2.2414 - val_mse:  0.9231\n",
      "Epoch 2/20\n",
      "2s - loss:  0.8024 - mse:  0.8033 - val_mse:  0.8614\n",
      "Epoch 3/20\n",
      "2s - loss:  0.6358 - mse:  0.6362 - val_mse:  0.8842\n",
      "Epoch 4/20\n",
      "2s - loss:  0.5181 - mse:  0.5187 - val_mse:  0.9410\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4468 - mse:  0.4466 - val_mse:  0.9888\n",
      "Epoch 6/20\n",
      "2s - loss:  0.4073 - mse:  0.4072 - val_mse:  1.0336\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3850 - mse:  0.3850 - val_mse:  1.0386\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3693 - mse:  0.3695 - val_mse:  1.0488\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3596 - mse:  0.3594 - val_mse:  1.0697\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3519 - mse:  0.3514 - val_mse:  1.0730\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3469 - mse:  0.3469 - val_mse:  1.0768\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3418 - mse:  0.3420 - val_mse:  1.0824\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3364 - mse:  0.3365 - val_mse:  1.1013\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3325 - mse:  0.3325 - val_mse:  1.0956\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3286 - mse:  0.3287 - val_mse:  1.0929\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3258 - mse:  0.3256 - val_mse:  1.1055\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3208 - mse:  0.3206 - val_mse:  1.1108\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3178 - mse:  0.3178 - val_mse:  1.1161\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3129 - mse:  0.3128 - val_mse:  1.1251\n",
      "Epoch 20/20\n",
      "2s - loss:  0.3085 - mse:  0.3090 - val_mse:  1.1224\n",
      "test MSE : 1.0513\n",
      "test ndcg : 0.6461\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "DeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.1468 - mse:  2.1435 - val_mse:  0.8804\n",
      "Epoch 2/20\n",
      "2s - loss:  0.6969 - mse:  0.6968 - val_mse:  0.9204\n",
      "Epoch 3/20\n",
      "2s - loss:  0.5088 - mse:  0.5089 - val_mse:  0.9785\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4438 - mse:  0.4445 - val_mse:  1.0244\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4148 - mse:  0.4152 - val_mse:  1.0451\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3981 - mse:  0.3986 - val_mse:  1.0670\n",
      "Epoch 7/20\n",
      "2s - loss:  0.3872 - mse:  0.3871 - val_mse:  1.0524\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3797 - mse:  0.3801 - val_mse:  1.0716\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3732 - mse:  0.3731 - val_mse:  1.0739\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3684 - mse:  0.3683 - val_mse:  1.0690\n",
      "Epoch 11/20\n",
      "2s - loss:  0.3646 - mse:  0.3644 - val_mse:  1.0812\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3618 - mse:  0.3619 - val_mse:  1.0916\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3589 - mse:  0.3585 - val_mse:  1.0925\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3557 - mse:  0.3561 - val_mse:  1.0954\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3539 - mse:  0.3542 - val_mse:  1.0951\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3516 - mse:  0.3515 - val_mse:  1.0942\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3507 - mse:  0.3513 - val_mse:  1.1014\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3486 - mse:  0.3490 - val_mse:  1.0955\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3470 - mse:  0.3467 - val_mse:  1.1135\n",
      "Epoch 20/20\n",
      "2s - loss:  0.3459 - mse:  0.3459 - val_mse:  1.1021\n",
      "test MSE : 1.0417\n",
      "test ndcg : 0.6407\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "AFM\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  9.6553 - mse:  9.6391 - val_mse:  3.4347\n",
      "Epoch 2/20\n",
      "2s - loss:  1.4456 - mse:  1.4450 - val_mse:  1.1750\n",
      "Epoch 3/20\n",
      "2s - loss:  1.1289 - mse:  1.1290 - val_mse:  1.1078\n",
      "Epoch 4/20\n",
      "2s - loss:  1.0492 - mse:  1.0488 - val_mse:  1.0493\n",
      "Epoch 5/20\n",
      "2s - loss:  0.9762 - mse:  0.9763 - val_mse:  0.9980\n",
      "Epoch 6/20\n",
      "2s - loss:  0.9087 - mse:  0.9084 - val_mse:  0.9554\n",
      "Epoch 7/20\n",
      "2s - loss:  0.8436 - mse:  0.8435 - val_mse:  0.9208\n",
      "Epoch 8/20\n",
      "2s - loss:  0.7734 - mse:  0.7732 - val_mse:  0.8953\n",
      "Epoch 9/20\n",
      "2s - loss:  0.6969 - mse:  0.6967 - val_mse:  0.8808\n",
      "Epoch 10/20\n",
      "2s - loss:  0.6266 - mse:  0.6268 - val_mse:  0.8873\n",
      "Epoch 11/20\n",
      "2s - loss:  0.5679 - mse:  0.5680 - val_mse:  0.9101\n",
      "Epoch 12/20\n",
      "2s - loss:  0.5202 - mse:  0.5197 - val_mse:  0.9276\n",
      "Epoch 13/20\n",
      "2s - loss:  0.4819 - mse:  0.4816 - val_mse:  0.9590\n",
      "Epoch 14/20\n",
      "2s - loss:  0.4504 - mse:  0.4500 - val_mse:  0.9764\n",
      "Epoch 15/20\n",
      "2s - loss:  0.4249 - mse:  0.4252 - val_mse:  1.0011\n",
      "Epoch 16/20\n",
      "2s - loss:  0.4013 - mse:  0.4013 - val_mse:  1.0294\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3817 - mse:  0.3817 - val_mse:  1.0524\n",
      "Epoch 18/20\n",
      "2s - loss:  0.3652 - mse:  0.3653 - val_mse:  1.0652\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3527 - mse:  0.3521 - val_mse:  1.0943\n",
      "Epoch 20/20\n",
      "2s - loss:  0.3424 - mse:  0.3426 - val_mse:  1.0946\n",
      "test MSE : 1.0347\n",
      "test ndcg : 0.6223\n",
      "['user', 'movie', 'time', 'age', 'occupation']\n",
      "xDeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 72000 samples, validate on 8000 samples, 282 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  1.5097 - mse:  1.5079 - val_mse:  0.8731\n",
      "Epoch 2/20\n",
      "3s - loss:  0.6758 - mse:  0.6753 - val_mse:  0.9178\n",
      "Epoch 3/20\n",
      "3s - loss:  0.4992 - mse:  0.4991 - val_mse:  0.9781\n",
      "Epoch 4/20\n",
      "2s - loss:  0.4386 - mse:  0.4389 - val_mse:  1.0063\n",
      "Epoch 5/20\n",
      "2s - loss:  0.4068 - mse:  0.4068 - val_mse:  1.0560\n",
      "Epoch 6/20\n",
      "2s - loss:  0.3884 - mse:  0.3886 - val_mse:  1.0407\n",
      "Epoch 7/20\n",
      "3s - loss:  0.3765 - mse:  0.3765 - val_mse:  1.0510\n",
      "Epoch 8/20\n",
      "2s - loss:  0.3682 - mse:  0.3681 - val_mse:  1.0721\n",
      "Epoch 9/20\n",
      "2s - loss:  0.3626 - mse:  0.3623 - val_mse:  1.0779\n",
      "Epoch 10/20\n",
      "2s - loss:  0.3563 - mse:  0.3567 - val_mse:  1.0775\n",
      "Epoch 11/20\n",
      "3s - loss:  0.3521 - mse:  0.3521 - val_mse:  1.0758\n",
      "Epoch 12/20\n",
      "2s - loss:  0.3480 - mse:  0.3481 - val_mse:  1.0966\n",
      "Epoch 13/20\n",
      "2s - loss:  0.3436 - mse:  0.3441 - val_mse:  1.1285\n",
      "Epoch 14/20\n",
      "2s - loss:  0.3392 - mse:  0.3398 - val_mse:  1.0996\n",
      "Epoch 15/20\n",
      "2s - loss:  0.3352 - mse:  0.3353 - val_mse:  1.1061\n",
      "Epoch 16/20\n",
      "2s - loss:  0.3315 - mse:  0.3313 - val_mse:  1.1026\n",
      "Epoch 17/20\n",
      "2s - loss:  0.3264 - mse:  0.3269 - val_mse:  1.1198\n",
      "Epoch 18/20\n",
      "3s - loss:  0.3192 - mse:  0.3197 - val_mse:  1.1292\n",
      "Epoch 19/20\n",
      "2s - loss:  0.3101 - mse:  0.3099 - val_mse:  1.1432\n",
      "Epoch 20/20\n",
      "3s - loss:  0.3000 - mse:  0.3001 - val_mse:  1.1487\n",
      "test MSE : 1.0697\n",
      "test ndcg : 0.6394\n",
      "['user', 'business']\n",
      "IPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  1.9390 - mse:  1.9387 - val_mse:  1.0469\n",
      "Epoch 2/20\n",
      "2s - loss:  0.9629 - mse:  0.9630 - val_mse:  1.0384\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9015 - mse:  0.9015 - val_mse:  1.0381\n",
      "Epoch 4/20\n",
      "2s - loss:  0.8738 - mse:  0.8738 - val_mse:  1.0478\n",
      "Epoch 5/20\n",
      "2s - loss:  0.8532 - mse:  0.8532 - val_mse:  1.0600\n",
      "Epoch 6/20\n",
      "2s - loss:  0.8293 - mse:  0.8293 - val_mse:  1.0599\n",
      "Epoch 7/20\n",
      "2s - loss:  0.8032 - mse:  0.8032 - val_mse:  1.0826\n",
      "Epoch 8/20\n",
      "2s - loss:  0.7788 - mse:  0.7788 - val_mse:  1.0976\n",
      "Epoch 9/20\n",
      "2s - loss:  0.7591 - mse:  0.7591 - val_mse:  1.1230\n",
      "Epoch 10/20\n",
      "2s - loss:  0.7436 - mse:  0.7435 - val_mse:  1.1519\n",
      "Epoch 11/20\n",
      "2s - loss:  0.7311 - mse:  0.7310 - val_mse:  1.1645\n",
      "Epoch 12/20\n",
      "2s - loss:  0.7200 - mse:  0.7200 - val_mse:  1.1760\n",
      "Epoch 13/20\n",
      "2s - loss:  0.7078 - mse:  0.7078 - val_mse:  1.1948\n",
      "Epoch 14/20\n",
      "2s - loss:  0.6915 - mse:  0.6915 - val_mse:  1.2148\n",
      "Epoch 15/20\n",
      "2s - loss:  0.6665 - mse:  0.6665 - val_mse:  1.2552\n",
      "Epoch 16/20\n",
      "2s - loss:  0.6346 - mse:  0.6346 - val_mse:  1.2761\n",
      "Epoch 17/20\n",
      "2s - loss:  0.6030 - mse:  0.6030 - val_mse:  1.3403\n",
      "Epoch 18/20\n",
      "2s - loss:  0.5751 - mse:  0.5751 - val_mse:  1.3586\n",
      "Epoch 19/20\n",
      "2s - loss:  0.5527 - mse:  0.5526 - val_mse:  1.4023\n",
      "Epoch 20/20\n",
      "2s - loss:  0.5345 - mse:  0.5344 - val_mse:  1.4462\n",
      "test MSE : 1.2151\n",
      "test ndcg : 0.7094\n",
      "['user', 'business']\n",
      "OPNN\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  1.9686 - mse:  1.9684 - val_mse:  1.0494\n",
      "Epoch 2/20\n",
      "2s - loss:  0.9634 - mse:  0.9634 - val_mse:  1.0321\n",
      "Epoch 3/20\n",
      "2s - loss:  0.9006 - mse:  0.9007 - val_mse:  1.0364\n",
      "Epoch 4/20\n",
      "2s - loss:  0.8736 - mse:  0.8736 - val_mse:  1.0448\n",
      "Epoch 5/20\n",
      "2s - loss:  0.8561 - mse:  0.8561 - val_mse:  1.0580\n",
      "Epoch 6/20\n",
      "3s - loss:  0.8446 - mse:  0.8445 - val_mse:  1.0684\n",
      "Epoch 7/20\n",
      "2s - loss:  0.8330 - mse:  0.8329 - val_mse:  1.0683\n",
      "Epoch 8/20\n",
      "2s - loss:  0.8160 - mse:  0.8160 - val_mse:  1.0696\n",
      "Epoch 9/20\n",
      "2s - loss:  0.7912 - mse:  0.7912 - val_mse:  1.0876\n",
      "Epoch 10/20\n",
      "3s - loss:  0.7670 - mse:  0.7670 - val_mse:  1.1058\n",
      "Epoch 11/20\n",
      "2s - loss:  0.7477 - mse:  0.7477 - val_mse:  1.1484\n",
      "Epoch 12/20\n",
      "2s - loss:  0.7323 - mse:  0.7323 - val_mse:  1.1593\n",
      "Epoch 13/20\n",
      "3s - loss:  0.7164 - mse:  0.7164 - val_mse:  1.1639\n",
      "Epoch 14/20\n",
      "2s - loss:  0.6972 - mse:  0.6972 - val_mse:  1.2014\n",
      "Epoch 15/20\n",
      "2s - loss:  0.6762 - mse:  0.6762 - val_mse:  1.2032\n",
      "Epoch 16/20\n",
      "2s - loss:  0.6542 - mse:  0.6542 - val_mse:  1.2377\n",
      "Epoch 17/20\n",
      "3s - loss:  0.6341 - mse:  0.6341 - val_mse:  1.2766\n",
      "Epoch 18/20\n",
      "2s - loss:  0.6150 - mse:  0.6150 - val_mse:  1.2909\n",
      "Epoch 19/20\n",
      "2s - loss:  0.5986 - mse:  0.5986 - val_mse:  1.3579\n",
      "Epoch 20/20\n",
      "3s - loss:  0.5817 - mse:  0.5817 - val_mse:  1.3570\n",
      "test MSE : 1.1732\n",
      "test ndcg : 0.7111\n",
      "['user', 'business']\n",
      "PNN\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "2s - loss:  2.0347 - mse:  2.0344 - val_mse:  1.0450\n",
      "Epoch 2/20\n",
      "2s - loss:  0.9638 - mse:  0.9638 - val_mse:  1.0281\n",
      "Epoch 3/20\n",
      "2s - loss:  0.9005 - mse:  0.9005 - val_mse:  1.0384\n",
      "Epoch 4/20\n",
      "3s - loss:  0.8725 - mse:  0.8725 - val_mse:  1.0434\n",
      "Epoch 5/20\n",
      "3s - loss:  0.8554 - mse:  0.8554 - val_mse:  1.0551\n",
      "Epoch 6/20\n",
      "2s - loss:  0.8452 - mse:  0.8452 - val_mse:  1.0630\n",
      "Epoch 7/20\n",
      "3s - loss:  0.8356 - mse:  0.8357 - val_mse:  1.0633\n",
      "Epoch 8/20\n",
      "3s - loss:  0.8192 - mse:  0.8192 - val_mse:  1.0716\n",
      "Epoch 9/20\n",
      "3s - loss:  0.7957 - mse:  0.7957 - val_mse:  1.0985\n",
      "Epoch 10/20\n",
      "3s - loss:  0.7702 - mse:  0.7702 - val_mse:  1.1056\n",
      "Epoch 11/20\n",
      "3s - loss:  0.7500 - mse:  0.7499 - val_mse:  1.1358\n",
      "Epoch 12/20\n",
      "3s - loss:  0.7336 - mse:  0.7336 - val_mse:  1.1525\n",
      "Epoch 13/20\n",
      "2s - loss:  0.7192 - mse:  0.7192 - val_mse:  1.1600\n",
      "Epoch 14/20\n",
      "3s - loss:  0.7038 - mse:  0.7038 - val_mse:  1.1810\n",
      "Epoch 15/20\n",
      "3s - loss:  0.6877 - mse:  0.6877 - val_mse:  1.2038\n",
      "Epoch 16/20\n",
      "3s - loss:  0.6711 - mse:  0.6710 - val_mse:  1.2334\n",
      "Epoch 17/20\n",
      "3s - loss:  0.6540 - mse:  0.6540 - val_mse:  1.2531\n",
      "Epoch 18/20\n",
      "3s - loss:  0.6382 - mse:  0.6381 - val_mse:  1.2706\n",
      "Epoch 19/20\n",
      "3s - loss:  0.6227 - mse:  0.6226 - val_mse:  1.2913\n",
      "Epoch 20/20\n",
      "3s - loss:  0.6092 - mse:  0.6091 - val_mse:  1.3174\n",
      "test MSE : 1.1627\n",
      "test ndcg : 0.7099\n",
      "['user', 'business']\n",
      "CCPM\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  1.9809 - mse:  1.9806 - val_mse:  1.1072\n",
      "Epoch 2/20\n",
      "3s - loss:  1.0046 - mse:  1.0046 - val_mse:  1.0325\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9140 - mse:  0.9140 - val_mse:  1.0316\n",
      "Epoch 4/20\n",
      "3s - loss:  0.8767 - mse:  0.8767 - val_mse:  1.0455\n",
      "Epoch 5/20\n",
      "3s - loss:  0.8556 - mse:  0.8556 - val_mse:  1.0486\n",
      "Epoch 6/20\n",
      "3s - loss:  0.8429 - mse:  0.8429 - val_mse:  1.0531\n",
      "Epoch 7/20\n",
      "3s - loss:  0.8332 - mse:  0.8331 - val_mse:  1.0641\n",
      "Epoch 8/20\n",
      "3s - loss:  0.8271 - mse:  0.8270 - val_mse:  1.0652\n",
      "Epoch 9/20\n",
      "3s - loss:  0.8209 - mse:  0.8209 - val_mse:  1.0746\n",
      "Epoch 10/20\n",
      "3s - loss:  0.8162 - mse:  0.8162 - val_mse:  1.0808\n",
      "Epoch 11/20\n",
      "3s - loss:  0.8127 - mse:  0.8127 - val_mse:  1.0823\n",
      "Epoch 12/20\n",
      "3s - loss:  0.8086 - mse:  0.8086 - val_mse:  1.0837\n",
      "Epoch 13/20\n",
      "3s - loss:  0.8028 - mse:  0.8028 - val_mse:  1.0872\n",
      "Epoch 14/20\n",
      "3s - loss:  0.7987 - mse:  0.7987 - val_mse:  1.1032\n",
      "Epoch 15/20\n",
      "3s - loss:  0.7943 - mse:  0.7942 - val_mse:  1.0992\n",
      "Epoch 16/20\n",
      "3s - loss:  0.7895 - mse:  0.7895 - val_mse:  1.1053\n",
      "Epoch 17/20\n",
      "3s - loss:  0.7823 - mse:  0.7822 - val_mse:  1.1152\n",
      "Epoch 18/20\n",
      "3s - loss:  0.7740 - mse:  0.7739 - val_mse:  1.1127\n",
      "Epoch 19/20\n",
      "3s - loss:  0.7630 - mse:  0.7629 - val_mse:  1.1303\n",
      "Epoch 20/20\n",
      "3s - loss:  0.7494 - mse:  0.7493 - val_mse:  1.1403\n",
      "test MSE : 1.0883\n",
      "test ndcg : 0.7081\n",
      "['user', 'business']\n",
      "WDL\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  1.6263 - mse:  1.6262 - val_mse:  1.0419\n",
      "Epoch 2/20\n",
      "2s - loss:  0.9597 - mse:  0.9598 - val_mse:  1.0333\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9034 - mse:  0.9033 - val_mse:  1.0379\n",
      "Epoch 4/20\n",
      "3s - loss:  0.8773 - mse:  0.8774 - val_mse:  1.0436\n",
      "Epoch 5/20\n",
      "3s - loss:  0.8635 - mse:  0.8635 - val_mse:  1.0543\n",
      "Epoch 6/20\n",
      "3s - loss:  0.8540 - mse:  0.8540 - val_mse:  1.0618\n",
      "Epoch 7/20\n",
      "3s - loss:  0.8482 - mse:  0.8481 - val_mse:  1.0715\n",
      "Epoch 8/20\n",
      "3s - loss:  0.8431 - mse:  0.8432 - val_mse:  1.0727\n",
      "Epoch 9/20\n",
      "3s - loss:  0.8389 - mse:  0.8389 - val_mse:  1.0757\n",
      "Epoch 10/20\n",
      "3s - loss:  0.8353 - mse:  0.8353 - val_mse:  1.0747\n",
      "Epoch 11/20\n",
      "3s - loss:  0.8342 - mse:  0.8343 - val_mse:  1.0727\n",
      "Epoch 12/20\n",
      "3s - loss:  0.8294 - mse:  0.8293 - val_mse:  1.0834\n",
      "Epoch 13/20\n",
      "3s - loss:  0.8275 - mse:  0.8274 - val_mse:  1.0869\n",
      "Epoch 14/20\n",
      "3s - loss:  0.8262 - mse:  0.8262 - val_mse:  1.0884\n",
      "Epoch 15/20\n",
      "3s - loss:  0.8241 - mse:  0.8241 - val_mse:  1.0887\n",
      "Epoch 16/20\n",
      "3s - loss:  0.8226 - mse:  0.8226 - val_mse:  1.0888\n",
      "Epoch 17/20\n",
      "3s - loss:  0.8221 - mse:  0.8221 - val_mse:  1.0949\n",
      "Epoch 18/20\n",
      "3s - loss:  0.8202 - mse:  0.8201 - val_mse:  1.0914\n",
      "Epoch 19/20\n",
      "3s - loss:  0.8191 - mse:  0.8190 - val_mse:  1.0907\n",
      "Epoch 20/20\n",
      "3s - loss:  0.8178 - mse:  0.8178 - val_mse:  1.0959\n",
      "test MSE : 1.0656\n",
      "test ndcg : 0.7119\n",
      "['user', 'business']\n",
      "DCN\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  1.9010 - mse:  1.9007 - val_mse:  1.0433\n",
      "Epoch 2/20\n",
      "3s - loss:  0.9619 - mse:  0.9619 - val_mse:  1.0296\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9020 - mse:  0.9020 - val_mse:  1.0387\n",
      "Epoch 4/20\n",
      "3s - loss:  0.8759 - mse:  0.8759 - val_mse:  1.0462\n",
      "Epoch 5/20\n",
      "4s - loss:  0.8613 - mse:  0.8613 - val_mse:  1.0521\n",
      "Epoch 6/20\n",
      "4s - loss:  0.8511 - mse:  0.8511 - val_mse:  1.0640\n",
      "Epoch 7/20\n",
      "4s - loss:  0.8431 - mse:  0.8431 - val_mse:  1.0686\n",
      "Epoch 8/20\n",
      "3s - loss:  0.8368 - mse:  0.8367 - val_mse:  1.0674\n",
      "Epoch 9/20\n",
      "4s - loss:  0.8316 - mse:  0.8315 - val_mse:  1.0753\n",
      "Epoch 10/20\n",
      "4s - loss:  0.8263 - mse:  0.8263 - val_mse:  1.0821\n",
      "Epoch 11/20\n",
      "3s - loss:  0.8216 - mse:  0.8216 - val_mse:  1.0812\n",
      "Epoch 12/20\n",
      "4s - loss:  0.8186 - mse:  0.8186 - val_mse:  1.0864\n",
      "Epoch 13/20\n",
      "3s - loss:  0.8126 - mse:  0.8125 - val_mse:  1.0817\n",
      "Epoch 14/20\n",
      "3s - loss:  0.8065 - mse:  0.8065 - val_mse:  1.0911\n",
      "Epoch 15/20\n",
      "4s - loss:  0.7998 - mse:  0.7997 - val_mse:  1.0861\n",
      "Epoch 16/20\n",
      "4s - loss:  0.7897 - mse:  0.7897 - val_mse:  1.0880\n",
      "Epoch 17/20\n",
      "3s - loss:  0.7787 - mse:  0.7787 - val_mse:  1.1155\n",
      "Epoch 18/20\n",
      "4s - loss:  0.7669 - mse:  0.7669 - val_mse:  1.1328\n",
      "Epoch 19/20\n",
      "4s - loss:  0.7555 - mse:  0.7554 - val_mse:  1.1438\n",
      "Epoch 20/20\n",
      "4s - loss:  0.7423 - mse:  0.7423 - val_mse:  1.1593\n",
      "test MSE : 1.0989\n",
      "test ndcg : 0.7089\n",
      "['user', 'business']\n",
      "NFM\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  2.0996 - mse:  2.0993 - val_mse:  1.2145\n",
      "Epoch 2/20\n",
      "3s - loss:  1.1619 - mse:  1.1618 - val_mse:  1.1718\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9602 - mse:  0.9601 - val_mse:  1.2314\n",
      "Epoch 4/20\n",
      "3s - loss:  0.7804 - mse:  0.7804 - val_mse:  1.3016\n",
      "Epoch 5/20\n",
      "3s - loss:  0.6721 - mse:  0.6721 - val_mse:  1.3453\n",
      "Epoch 6/20\n",
      "3s - loss:  0.6059 - mse:  0.6059 - val_mse:  1.3792\n",
      "Epoch 7/20\n",
      "3s - loss:  0.5629 - mse:  0.5629 - val_mse:  1.4148\n",
      "Epoch 8/20\n",
      "3s - loss:  0.5320 - mse:  0.5320 - val_mse:  1.4341\n",
      "Epoch 9/20\n",
      "3s - loss:  0.5086 - mse:  0.5085 - val_mse:  1.4707\n",
      "Epoch 10/20\n",
      "3s - loss:  0.4911 - mse:  0.4910 - val_mse:  1.4897\n",
      "Epoch 11/20\n",
      "3s - loss:  0.4757 - mse:  0.4756 - val_mse:  1.5000\n",
      "Epoch 12/20\n",
      "3s - loss:  0.4634 - mse:  0.4634 - val_mse:  1.5563\n",
      "Epoch 13/20\n",
      "3s - loss:  0.4526 - mse:  0.4526 - val_mse:  1.5540\n",
      "Epoch 14/20\n",
      "3s - loss:  0.4438 - mse:  0.4437 - val_mse:  1.5772\n",
      "Epoch 15/20\n",
      "3s - loss:  0.4352 - mse:  0.4352 - val_mse:  1.6115\n",
      "Epoch 16/20\n",
      "3s - loss:  0.4281 - mse:  0.4281 - val_mse:  1.6354\n",
      "Epoch 17/20\n",
      "3s - loss:  0.4221 - mse:  0.4220 - val_mse:  1.6314\n",
      "Epoch 18/20\n",
      "3s - loss:  0.4159 - mse:  0.4158 - val_mse:  1.6444\n",
      "Epoch 19/20\n",
      "3s - loss:  0.4112 - mse:  0.4111 - val_mse:  1.6559\n",
      "Epoch 20/20\n",
      "3s - loss:  0.4061 - mse:  0.4059 - val_mse:  1.7126\n",
      "test MSE : 1.3224\n",
      "test ndcg : 0.6991\n",
      "['user', 'business']\n",
      "DeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  1.6248 - mse:  1.6246 - val_mse:  1.0397\n",
      "Epoch 2/20\n",
      "3s - loss:  0.9584 - mse:  0.9583 - val_mse:  1.0308\n",
      "Epoch 3/20\n",
      "3s - loss:  0.9021 - mse:  0.9021 - val_mse:  1.0383\n",
      "Epoch 4/20\n",
      "3s - loss:  0.8779 - mse:  0.8778 - val_mse:  1.0480\n",
      "Epoch 5/20\n",
      "3s - loss:  0.8634 - mse:  0.8634 - val_mse:  1.0560\n",
      "Epoch 6/20\n",
      "3s - loss:  0.8544 - mse:  0.8544 - val_mse:  1.0652\n",
      "Epoch 7/20\n",
      "3s - loss:  0.8471 - mse:  0.8471 - val_mse:  1.0644\n",
      "Epoch 8/20\n",
      "3s - loss:  0.8424 - mse:  0.8424 - val_mse:  1.0659\n",
      "Epoch 9/20\n",
      "3s - loss:  0.8381 - mse:  0.8381 - val_mse:  1.0772\n",
      "Epoch 10/20\n",
      "3s - loss:  0.8354 - mse:  0.8354 - val_mse:  1.0722\n",
      "Epoch 11/20\n",
      "3s - loss:  0.8317 - mse:  0.8316 - val_mse:  1.0802\n",
      "Epoch 12/20\n",
      "3s - loss:  0.8291 - mse:  0.8291 - val_mse:  1.0796\n",
      "Epoch 13/20\n",
      "3s - loss:  0.8279 - mse:  0.8279 - val_mse:  1.0844\n",
      "Epoch 14/20\n",
      "3s - loss:  0.8240 - mse:  0.8239 - val_mse:  1.0833\n",
      "Epoch 15/20\n",
      "3s - loss:  0.8227 - mse:  0.8228 - val_mse:  1.0836\n",
      "Epoch 16/20\n",
      "3s - loss:  0.8205 - mse:  0.8205 - val_mse:  1.0834\n",
      "Epoch 17/20\n",
      "3s - loss:  0.8182 - mse:  0.8182 - val_mse:  1.1041\n",
      "Epoch 18/20\n",
      "3s - loss:  0.8168 - mse:  0.8168 - val_mse:  1.0865\n",
      "Epoch 19/20\n",
      "3s - loss:  0.8151 - mse:  0.8151 - val_mse:  1.0836\n",
      "Epoch 20/20\n",
      "3s - loss:  0.8141 - mse:  0.8141 - val_mse:  1.0884\n",
      "test MSE : 1.0628\n",
      "test ndcg : 0.7083\n",
      "['user', 'business']\n",
      "AFM\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "3s - loss:  12.6932 - mse:  12.6923 - val_mse:  9.7416\n",
      "Epoch 2/20\n",
      "2s - loss:  6.6281 - mse:  6.6273 - val_mse:  4.2818\n",
      "Epoch 3/20\n",
      "3s - loss:  3.0695 - mse:  3.0691 - val_mse:  2.4757\n",
      "Epoch 4/20\n",
      "3s - loss:  1.9295 - mse:  1.9292 - val_mse:  1.8260\n",
      "Epoch 5/20\n",
      "3s - loss:  1.4603 - mse:  1.4601 - val_mse:  1.5307\n",
      "Epoch 6/20\n",
      "3s - loss:  1.2255 - mse:  1.2252 - val_mse:  1.3764\n",
      "Epoch 7/20\n",
      "3s - loss:  1.0926 - mse:  1.0923 - val_mse:  1.2893\n",
      "Epoch 8/20\n",
      "3s - loss:  1.0102 - mse:  1.0099 - val_mse:  1.2393\n",
      "Epoch 9/20\n",
      "3s - loss:  0.9564 - mse:  0.9562 - val_mse:  1.2080\n",
      "Epoch 10/20\n",
      "3s - loss:  0.9193 - mse:  0.9190 - val_mse:  1.1875\n",
      "Epoch 11/20\n",
      "3s - loss:  0.8926 - mse:  0.8922 - val_mse:  1.1756\n",
      "Epoch 12/20\n",
      "3s - loss:  0.8731 - mse:  0.8728 - val_mse:  1.1685\n",
      "Epoch 13/20\n",
      "3s - loss:  0.8578 - mse:  0.8575 - val_mse:  1.1659\n",
      "Epoch 14/20\n",
      "3s - loss:  0.8459 - mse:  0.8456 - val_mse:  1.1638\n",
      "Epoch 15/20\n",
      "3s - loss:  0.8364 - mse:  0.8360 - val_mse:  1.1628\n",
      "Epoch 16/20\n",
      "3s - loss:  0.8281 - mse:  0.8278 - val_mse:  1.1637\n",
      "Epoch 17/20\n",
      "3s - loss:  0.8210 - mse:  0.8206 - val_mse:  1.1655\n",
      "Epoch 18/20\n",
      "3s - loss:  0.8146 - mse:  0.8142 - val_mse:  1.1656\n",
      "Epoch 19/20\n",
      "3s - loss:  0.8082 - mse:  0.8078 - val_mse:  1.1679\n",
      "Epoch 20/20\n",
      "3s - loss:  0.8020 - mse:  0.8016 - val_mse:  1.1695\n",
      "test MSE : 1.0948\n",
      "test ndcg : 0.7101\n",
      "['user', 'business']\n",
      "xDeepFM\n",
      "==================\n",
      "cuda\n",
      "Train on 133081 samples, validate on 14787 samples, 520 steps per epoch\n",
      "Epoch 1/20\n",
      "4s - loss:  1.4228 - mse:  1.4226 - val_mse:  1.0419\n",
      "Epoch 2/20\n",
      "4s - loss:  0.9543 - mse:  0.9544 - val_mse:  1.0400\n",
      "Epoch 3/20\n",
      "4s - loss:  0.8998 - mse:  0.8999 - val_mse:  1.0450\n",
      "Epoch 4/20\n",
      "4s - loss:  0.8741 - mse:  0.8741 - val_mse:  1.0663\n",
      "Epoch 5/20\n",
      "4s - loss:  0.8563 - mse:  0.8563 - val_mse:  1.0543\n",
      "Epoch 6/20\n",
      "4s - loss:  0.8430 - mse:  0.8430 - val_mse:  1.0793\n",
      "Epoch 7/20\n",
      "4s - loss:  0.8315 - mse:  0.8314 - val_mse:  1.0985\n",
      "Epoch 8/20\n",
      "4s - loss:  0.8222 - mse:  0.8222 - val_mse:  1.0859\n",
      "Epoch 9/20\n",
      "4s - loss:  0.8133 - mse:  0.8133 - val_mse:  1.0948\n",
      "Epoch 10/20\n",
      "4s - loss:  0.8040 - mse:  0.8040 - val_mse:  1.1070\n",
      "Epoch 11/20\n",
      "4s - loss:  0.7927 - mse:  0.7927 - val_mse:  1.1350\n",
      "Epoch 12/20\n",
      "4s - loss:  0.7791 - mse:  0.7791 - val_mse:  1.1442\n",
      "Epoch 13/20\n",
      "5s - loss:  0.7599 - mse:  0.7599 - val_mse:  1.1450\n",
      "Epoch 14/20\n",
      "4s - loss:  0.7355 - mse:  0.7354 - val_mse:  1.1551\n",
      "Epoch 15/20\n",
      "4s - loss:  0.7037 - mse:  0.7037 - val_mse:  1.1638\n",
      "Epoch 16/20\n",
      "4s - loss:  0.6690 - mse:  0.6689 - val_mse:  1.2039\n",
      "Epoch 17/20\n",
      "4s - loss:  0.6343 - mse:  0.6343 - val_mse:  1.1909\n",
      "Epoch 18/20\n",
      "4s - loss:  0.6021 - mse:  0.6021 - val_mse:  1.2321\n",
      "Epoch 19/20\n",
      "4s - loss:  0.5741 - mse:  0.5741 - val_mse:  1.2395\n",
      "Epoch 20/20\n",
      "4s - loss:  0.5477 - mse:  0.5477 - val_mse:  1.3021\n",
      "test MSE : 1.1703\n",
      "test ndcg : 0.7194\n"
     ]
    }
   ],
   "source": [
    "# 73 min\n",
    "data_ls = [DoubanBook['user'], Movielens['user'], Yelp['user']]\n",
    "feats_ls = [['user', 'book', 'location'], ['user', 'movie', 'time', 'age', 'occupation'], ['user', 'business']]\n",
    "model = ['IPNN', 'OPNN', 'PNN', 'CCPM', 'WDL', 'DCN', 'NFM', 'DeepFM', 'AFM', 'xDeepFM']\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)    \n",
    "    \n",
    "for data, feats in zip(data_ls, feats_ls) :\n",
    "    nn = nn_based(data, feats, 'rating')\n",
    "    for m in model :\n",
    "        rmse_t, ndcg_t, recall_t = nn.train_model(m, config['n_epoch'])\n",
    "        name = feats[1] + m\n",
    "        rmse[name] = rmse_t\n",
    "        ndcg_10[name] = ndcg_t\n",
    "        recall_10[name] = recall_t\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"w\") as fp:\n",
    "    json.dump(rmse, fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"w\") as fp:\n",
    "    json.dump(ndcg_10, fp)\n",
    "with open(\"./metrics/recall.txt\", \"w\") as fp:\n",
    "    json.dump(recall_10, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3 Recent NN-based Methods\n",
    "* **Attention Factorization Machines(AFM)**\n",
    "* Collaborative Memory Networks (CMN)\n",
    "* **xDeepFM**\n",
    "* **Deep Interest Network (DIN)** *done for movielens*\n",
    "* DeepGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recent nn-based approach\n",
    "from deepctr_torch.models import AFM\n",
    "from deepctr_torch.models import xDeepFM\n",
    "from deepctr_torch.models import DIN\n",
    "\n",
    "# Din\n",
    "import torch_rechub\n",
    "from torch_rechub.utils.data import create_seq_features, df_to_dict, DataGenerator\n",
    "from torch_rechub.basic.features import DenseFeature, SparseFeature, SequenceFeature\n",
    "from torch_rechub.models.ranking import DIN\n",
    "from torch_rechub.trainers import CTRTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:54<00:00, 86.77it/s, loss=0.401]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 104.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: auc: 0.8643540785539259\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:53<00:00, 88.32it/s, loss=0.327]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 104.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 validation: auc: 0.884261888402461\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:52<00:00, 90.09it/s, loss=0.28] \n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 104.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 validation: auc: 0.9320831398179812\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:52<00:00, 90.78it/s, loss=0.298]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 107.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 validation: auc: 0.9476007282549657\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:55<00:00, 85.17it/s, loss=0.288]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 109.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 validation: auc: 0.9526161963634483\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:55<00:00, 85.86it/s, loss=0.274]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 102.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 validation: auc: 0.9564733837204202\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:54<00:00, 87.95it/s, loss=0.166]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 100.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 validation: auc: 0.9545363559587923\n",
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:55<00:00, 85.70it/s, loss=0.25] \n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 102.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 validation: auc: 0.9621422121363082\n",
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:53<00:00, 88.27it/s, loss=0.239]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 96.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 validation: auc: 0.9655439590036087\n",
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:53<00:00, 89.01it/s, loss=0.203]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 103.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 validation: auc: 0.9655765707917581\n",
      "epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [01:00<00:00, 78.40it/s, loss=0.207]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 104.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 validation: auc: 0.9659420477279144\n",
      "epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:56<00:00, 84.76it/s, loss=0.229]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 103.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 validation: auc: 0.9653257973863338\n",
      "epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:52<00:00, 90.42it/s, loss=0.235] \n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 102.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 validation: auc: 0.9637188234116654\n",
      "epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:51<00:00, 92.28it/s, loss=0.27] \n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 101.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 validation: auc: 0.9607252861684411\n",
      "epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:53<00:00, 89.18it/s, loss=0.205]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 106.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 validation: auc: 0.9667708369646747\n",
      "epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:54<00:00, 87.94it/s, loss=0.216]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 87.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 validation: auc: 0.9640246994936177\n",
      "epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:56<00:00, 83.84it/s, loss=0.238]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 103.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 validation: auc: 0.9636918343456109\n",
      "epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:52<00:00, 90.75it/s, loss=0.198]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 101.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 validation: auc: 0.9670812112243027\n",
      "epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:57<00:00, 82.84it/s, loss=0.233]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 105.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 validation: auc: 0.9655495817257034\n",
      "epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 4756/4756 [00:59<00:00, 80.58it/s, loss=0.261]\n",
      "validation: 100%|██████████| 118/118 [00:01<00:00, 101.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 validation: auc: 0.9676884652105316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation: 100%|██████████| 118/118 [00:01<00:00, 99.73it/s] \n",
      "predict: 100%|██████████| 118/118 [00:01<00:00, 107.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 0.9748248240931393\n",
      "0.2500980843297598\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/rita/miniconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Din\n",
    "# need to have 'time' variable, so only movielens can be used\n",
    "# https://www.cnblogs.com/junwei-kuang/p/DIN-DeepFM.html\n",
    "# feature engeering\n",
    "# 8 mins\n",
    "# 7 epochs\n",
    "data = Movielens['user_movie'].copy(deep = True)\n",
    "data.columns = ['user_id', 'item_id', 'cate_id', 'time']\n",
    "\n",
    "\n",
    "train, val, test = create_seq_features(data, seq_feature_col=['item_id', 'cate_id'], drop_short=3)\n",
    "# get size of category data\n",
    "n_users, n_items, n_cates = data[\"user_id\"].max(), data[\"item_id\"].max(), data[\"cate_id\"].max()\n",
    "\n",
    "features = [SparseFeature(\"target_item\", vocab_size=n_items + 2, embed_dim=8), \n",
    "            SparseFeature(\"target_cate\", vocab_size=n_cates + 2, embed_dim=8),\n",
    "            SparseFeature(\"user_id\", vocab_size=n_users + 2, embed_dim=8)]\n",
    "target_features = features  \n",
    "history_features = [\n",
    "    SequenceFeature(\"history_item\", vocab_size=n_items + 2, embed_dim=8, pooling=\"concat\", shared_with=\"target_item\"),\n",
    "    SequenceFeature(\"history_cate\", vocab_size=n_cates + 2, embed_dim=8, pooling=\"concat\", shared_with=\"target_cate\")]\n",
    "\n",
    "\n",
    "train = df_to_dict(train)\n",
    "val = df_to_dict(val)\n",
    "test = df_to_dict(test)\n",
    "\n",
    "train_y, val_y, test_y = train[\"label\"], val[\"label\"], test[\"label\"]\n",
    "\n",
    "del train[\"label\"]\n",
    "del val[\"label\"]\n",
    "del test[\"label\"]\n",
    "train_x, val_x, test_x = train, val, test\n",
    "\n",
    "dg = DataGenerator(train_x, train_y)\n",
    "train_dataloader, val_dataloader, test_dataloader = dg.generate_dataloader(x_val=val_x, y_val=val_y, x_test=test_x, y_test=test_y, batch_size=16)\n",
    "\n",
    "\n",
    "\n",
    "# 定义模型，模型的参数需要我们之前的feature类，用于构建模型的输入层，mlp指定模型后续DNN的结构，attention_mlp指定attention层的结构\n",
    "model = DIN(features=features, history_features=history_features, target_features=target_features, mlp_params={\"dims\": [256, 128]}, attention_mlp_params={\"dims\": [256, 128]})  # 这里的 features = target_features，理论上是不合理的，是为了特征太少来凑数？\n",
    "\n",
    "ctr_trainer = CTRTrainer(model, optimizer_params={\"lr\": 1e-3, \"weight_decay\": 1e-3}, n_epoch=config['n_epoch'], earlystop_patience=4, device='cuda', model_path='./') \n",
    "ctr_trainer.fit(train_dataloader, val_dataloader)\n",
    "\n",
    "auc = ctr_trainer.evaluate(ctr_trainer.model, test_dataloader)\n",
    "pred_y = np.array(ctr_trainer.predict(model, test_dataloader))\n",
    "r = sqrt(mean_squared_error(test_y, pred_y))\n",
    "\n",
    "test_y = np.where(test_y > 3, 1, 0)\n",
    "pred_y = np.where(pred_y > 3, 1, 0)\n",
    "\n",
    "n = ndcg_score(test_y.reshape(1, -1), pred_y.reshape(1, -1), k=10)\n",
    "re = recall_score(test_y.reshape(1, -1).squeeze(), pred_y.reshape(1, -1).squeeze())\n",
    "name = 'movieDIN' \n",
    "print(f'test auc: {auc}')\n",
    "\n",
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)\n",
    "    \n",
    "rmse[name] = r\n",
    "ndcg_10[name] = n\n",
    "recall_10[name] = re\n",
    "print(r, n, re, sep = '\\n')\n",
    "\n",
    "# with open(\"./metrics/rmse.txt\", \"w\") as fp:\n",
    "#     json.dump(rmse, fp)\n",
    "# with open(\"./metrics/ndcg.txt\", \"w\") as fp:\n",
    "#     json.dump(ndcg_10, fp)\n",
    "# with open(\"./metrics/recall.txt\", \"w\") as fp:\n",
    "#     json.dump(recall_10, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./metrics/rmse.txt\", \"r\") as fp:\n",
    "    rmse = json.load(fp)\n",
    "with open(\"./metrics/ndcg.txt\", \"r\") as fp:\n",
    "    ndcg_10 = json.load(fp)\n",
    "with open(\"./metrics/recall.txt\", \"r\") as fp:\n",
    "    recall_10 = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data       book                     movie                   business   \n",
      "metrics    rmse recall_10 ndcg_10    rmse recall_10 ndcg_10     rmse   \n",
      "UCF-s    0.7565       NaN     NaN  1.0173       NaN     NaN   1.1039  \\\n",
      "UCF-p    0.7739       NaN     NaN   1.012       NaN     NaN   1.1652   \n",
      "ICF-s    0.7563       NaN     NaN  1.0172       NaN     NaN   1.1049   \n",
      "ICF-p    0.7736       NaN     NaN   1.011       NaN     NaN    1.165   \n",
      "MF        0.486     0.994  0.7639    0.58    0.9269  0.6347    0.557   \n",
      "FM       0.7063     0.999  0.7587  0.9516     0.942  0.6238   1.0324   \n",
      "IPNN     0.7714    0.9808  0.7702  1.1151    0.8375   0.639   1.2151   \n",
      "OPNN      0.758    0.9803  0.7716  1.0561    0.8767  0.6347   1.1732   \n",
      "PNN      0.7598    0.9763  0.7732  1.1223    0.8485  0.6344   1.1627   \n",
      "CCPM     0.7356     0.986  0.7721  1.0622    0.8872  0.6287   1.0883   \n",
      "WDL      0.7139    0.9885  0.7715  1.0387     0.858  0.6488   1.0656   \n",
      "DCN       0.732    0.9882    0.77  1.0405    0.8937  0.6296   1.0989   \n",
      "NFM      0.7566     0.979  0.7742  1.0513    0.8648  0.6461   1.3224   \n",
      "DeepFM   0.7523    0.9753  0.7779  1.0697    0.8622  0.6394   1.1703   \n",
      "AFM       0.736    0.9885  0.7696  1.0347    0.8933  0.6223   1.0948   \n",
      "DIN         NaN       NaN     NaN   0.258       0.0     0.0      NaN   \n",
      "\n",
      "data                       \n",
      "metrics recall_10 ndcg_10  \n",
      "UCF-s         NaN     NaN  \n",
      "UCF-p         NaN     NaN  \n",
      "ICF-s         NaN     NaN  \n",
      "ICF-p         NaN     NaN  \n",
      "MF         0.9213  0.7069  \n",
      "FM         0.9888  0.6854  \n",
      "IPNN       0.8995  0.7094  \n",
      "OPNN       0.9004  0.7111  \n",
      "PNN        0.9078  0.7099  \n",
      "CCPM       0.9337  0.7081  \n",
      "WDL        0.9301  0.7119  \n",
      "DCN        0.9303  0.7089  \n",
      "NFM        0.8806  0.6991  \n",
      "DeepFM     0.8891  0.7194  \n",
      "AFM        0.9142  0.7101  \n",
      "DIN           NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "iterables = [['book', 'movie', 'business'], ['rmse', 'recall_10', 'ndcg_10']]\n",
    "# temp = pd.DataFrame(columns = ['book', 'movie', 'business'], index = model)\n",
    "model = ['UCF-s', 'UCF-p', 'ICF-s', 'ICF-p', 'MF', 'FM', 'IPNN', 'OPNN', 'PNN', 'CCPM', 'WDL', 'DCN', 'NFM', 'DeepFM', 'AFM', 'DIN']\n",
    "a = pd.MultiIndex.from_product(iterables, names = ['data', 'metrics'])\n",
    "temp = pd.DataFrame(columns = a, index = model)\n",
    "for i in temp.columns :\n",
    "    for j in temp.index :\n",
    "        for k in rmse.keys() :   \n",
    "            if (i[0] in k) and (j in k) :\n",
    "                t = sum([a.isupper() for a in k])\n",
    "                if (t == 2) and (j == 'FM'): \n",
    "                    temp.at['FM', (i[0], 'rmse')] = round(rmse[k], 4)\n",
    "                elif j != 'FM': \n",
    "                    # print(j)\n",
    "                    temp.at[j, (i[0], 'rmse')] = round(rmse[k], 4)\n",
    "                    \n",
    "        for k in ndcg_10.keys() :   \n",
    "            if (i[0] in k) and (j in k) :\n",
    "                t = sum([a.isupper() for a in k])\n",
    "                if (t == 2) and (j == 'FM'): \n",
    "                    temp.at['FM', (i[0], 'ndcg_10')] = round(ndcg_10[k], 4)\n",
    "                elif j != 'FM': \n",
    "                    # print(j)\n",
    "                    temp.at[j, (i[0], 'ndcg_10')] = round(ndcg_10[k], 4)\n",
    "                    \n",
    "        for k in recall_10.keys() :   \n",
    "            if (i[0] in k) and (j in k) :\n",
    "                t = sum([a.isupper() for a in k])\n",
    "                if (t == 2) and (j == 'FM'): \n",
    "                    temp.at['FM', (i[0], 'recall_10')] = round(recall_10[k], 4)\n",
    "                elif j != 'FM': \n",
    "                    # print(j)\n",
    "                    temp.at[j, (i[0], 'recall_10')] = round(recall_10[k], 4)\n",
    "\n",
    "# for i in temp.columns :\n",
    "#     for j in temp.index :\n",
    "#         for k in ndcg_10.keys() :   \n",
    "#             if (i[0] in k) and (j in k) :\n",
    "#                 t = sum([a.isupper() for a in k])\n",
    "#                 if (t == 2) and (j == 'FM'): \n",
    "#                     temp.at['FM', (i[0], 'ndcg_10')] = round(ndcg_10[k], 4)\n",
    "#                 elif j != 'FM': \n",
    "#                     # print(j)\n",
    "#                     temp.at[j, (i[0], 'ndcg_10')] = round(ndcg_10[k], 4)\n",
    "\n",
    "print(temp)\n",
    "# temp.to_csv('results.csv')\n",
    "temp.to_csv('results_round4.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data       book                     movie                   business   \n",
      "metrics    rmse recall_10 ndcg_10    rmse recall_10 ndcg_10     rmse   \n",
      "UCF-s    0.7565       NaN     NaN  1.0173       NaN     NaN   1.1039  \\\n",
      "UCF-p    0.7739       NaN     NaN  1.0120       NaN     NaN   1.1652   \n",
      "ICF-s    0.7563       NaN     NaN  1.0172       NaN     NaN   1.1049   \n",
      "ICF-p    0.7736       NaN     NaN  1.0110       NaN     NaN   1.1650   \n",
      "MF       0.4860    0.9940  0.7639  0.5800    0.9269  0.6347   0.5570   \n",
      "FM       0.7063    0.9990  0.7587  0.9516    0.9420  0.6238   1.0324   \n",
      "IPNN     0.7714    0.9808  0.7702  1.1151    0.8375  0.6390   1.2151   \n",
      "OPNN     0.7580    0.9803  0.7716  1.0561    0.8767  0.6347   1.1732   \n",
      "PNN      0.7598    0.9763  0.7732  1.1223    0.8485  0.6344   1.1627   \n",
      "CCPM     0.7356    0.9860  0.7721  1.0622    0.8872  0.6287   1.0883   \n",
      "WDL      0.7139    0.9885  0.7715  1.0387    0.8580  0.6488   1.0656   \n",
      "DCN      0.7320    0.9882  0.7700  1.0405    0.8937  0.6296   1.0989   \n",
      "NFM      0.7566    0.9790  0.7742  1.0513    0.8648  0.6461   1.3224   \n",
      "DeepFM   0.7523    0.9753  0.7779  1.0697    0.8622  0.6394   1.1703   \n",
      "AFM      0.7360    0.9885  0.7696  1.0347    0.8933  0.6223   1.0948   \n",
      "DIN         NaN       NaN     NaN  0.2580    0.0000  0.0000      NaN   \n",
      "\n",
      "data                       \n",
      "metrics recall_10 ndcg_10  \n",
      "UCF-s         NaN     NaN  \n",
      "UCF-p         NaN     NaN  \n",
      "ICF-s         NaN     NaN  \n",
      "ICF-p         NaN     NaN  \n",
      "MF         0.9213  0.7069  \n",
      "FM         0.9888  0.6854  \n",
      "IPNN       0.8995  0.7094  \n",
      "OPNN       0.9004  0.7111  \n",
      "PNN        0.9078  0.7099  \n",
      "CCPM       0.9337  0.7081  \n",
      "WDL        0.9301  0.7119  \n",
      "DCN        0.9303  0.7089  \n",
      "NFM        0.8806  0.6991  \n",
      "DeepFM     0.8891  0.7194  \n",
      "AFM        0.9142  0.7101  \n",
      "DIN           NaN     NaN  \n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv('results_round4.csv', header=[0,1], index_col = [0])\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
